May 28th 2013 ---------------------
Begin work on SLIMER. 

Image manipulation using python:
See
http://pythonvision.org/software

http://www.itk.org/

http://www.cellprofiler.org/

http://opencv.willowgarage.com/documentation/python/cookbook.html

http://scipy-lectures.github.io/advanced/image_processing/

http://scikit-image.org/

Also, don't forget about ImageMagick, which has python bindings.

http://code.google.com/p/priithon/

May 30th 2013 ---------------------------
Had a chat with Mary via phone today. Here are the Q&A:
1) procedure for centering scintillator?
There is a button down and to the right--turn on light. This will shine through the 
objective. Should try to focus this light down to ease alignment.  
The spot light is about the same as a source, but cover camera just in case.  


2) special handling precautions for scintillator? Has coating, don't touch base 
(top yellow portion). White on edges is oxidation. Glass side is bottom. 

3) Light settings when running? Is the box switched completely off? Switched off light.

4) Confirm temperature dependence setting? Readout noise may be temperature dependent. 
So it is a battle between readout noise and thermal noise. 
Thermal noise is a constant noise throughout all pixels: not "spikey" 


5) Camera calibration? How to do? Turn on camera, attachment ring turns to close shutter,
orange light comes on, and this activates the RapidCal, and takes a few minutes.
Once light turns green, it is done. Sometimes never turns to green.
In this case, repeat. Camera has to be fully cooled. May have to be set to coldest setting.

6) Had issues with filter wheels? Don't recall......Filters should help, not hurt.
Could see 241Am and 90Sr signals with filters. These are the SEMROCK filters. 
Their efficiency is quite high.

7) Readout speed used? 1 Mhz --> use slowest.

8) With the Ti-U, can't do z position with stage? How to focus?
Nope. Must manually focus (see below). 

9) Focus procedure? Manual? Look at edge of scintillator, can see fiber optic 
Use light for this, need to adjust down to low light levels. Use Live View 
in video mode. 

10) worry about objectives hitting the motorized stage?
Biggest objective would get really close to sample. biggest is 40X
Be careful. 


11) any mounts for holder on stage? Or just put scintillator on top?
Clamp scintillator on holder---should fit. 

12) SLIMER data on external rugged disk? Safe to wipe clean?
May have uploaded everything to WIT before, but can't recall.
Check first.
 
13) Manual for Nikon NIS Elements? There is one on the computer. 
It may be on the anti-priracy thumb drive.

14) Any other hints?

15) Your best idea of problems?

16) Anything hard to reproduce? No. 241Am plots could be reproduced consistenly. 

17) Anything special about nd2 file format? 
Maybe not. Maybe only way to take movies. 

18) Any solutions/thoughts about dynamic range issues?
Have a bunch of grey scale available on camera, everything is crowded
down by 300. Camera guys thought she was crazy when brought up. 
Nothing would really blow out a pixel. 
Normally played with gain of camera and total number of possible grey scale numbers. 
2^32. Never really helped. 
Noise is around grey value of 300....

19) Will need to chat again next week!!!!!!!!!!!

20) power input for firewire cable? Problems with board?
Microscope guy was missing a bracket to hold it still.
Should get bracket. 
But always worked. Cover was loose so bracket could be installed later. 
No idea about power.

21) What is the "1/3" next to gain setting?
This is the fractional gain thing. Couldn't see a difference.
Maybe gain without E/M on. 

22) What are LUTS? It is a noise histogram: number of pixels at a certain value. 
But not sure.  
 
23) Worry about exposing camera to ambient light? While on?
Never seemed to hurt it. Try not to shine light directly onto it.

24) No filters should be in place, correct? Filters don't help signals.
Filter is tuned to CsI output. Second? Look for empty boxes to find out what the second
was tuned to.

25) Always start with lowest power.....if not far enough back you may miss activity
Start with 4x. Only use 40x when everything is fine tuned. 
This is more a function of activity area. 
Objectives are manual. 
 
26) Mode setting is all on software. Needed to use EM mode and high gain (250)
to see 241Am. Readout noise is much worse in EM mode though. 

Other notes:
Mary thought that we had proof of principle in that we had some signals from radiation.
Cs137 and 90Sr --> clearly seeing signals, just couldn't get down to carbon 14 energies.

Different readout modes: BERT, some noise problems, including readout noise.
Noise obscures the C14. 
Maybe all readout noise? 
Camera was roughly $30k. 

May have seen the 59 keV x-ray from Am241, using a source that was encapsulated.
This was in the form of the shoulder 
C14 endpoint is 156 keV:

Noise is randomly distributed and is single pixel spikes: turning up readout rate,
this increases.

June 24th 2013 ----------------------------
Time to look at backgrounds. A few days ago, we took different data sets in order to study backgrounds. 
These data can be found here:
/proj3/Slimer/Slimer_mk2/6_11_2013

they are:
am241_6_11_2013_90msec --> data using am241
bi207_6_11_2013_90msec001 --> data using bi207
cs137_6_11_2013_90msec --> data using cs137
no_camera2_6_11_2013_90msec --> second run with camera shutter closed
no_camera_6_11_2013_90msec --> first run with camera shutter closed
no_lens_6_11_2013_90msec002 --> run with a blank lens selected, but with the camera shutter open
no_light_6_11_2013_90msec --> can't recall
no_source_6_11_2013_90msec001 --> run with an objective lense selected, and the CsI in place
with_lens_6_11_2013_90msec---> run with an objective lens selected, but no CsI in place

I'm interested in the background levels. There should be two, maybe three kinds of background:
1) random thermal noise--> shows up as a baseline for all pixels
2) readout noise --> shows up as single pixel "spikes"
3) fake hits --> large, distributed hits of many pixels, which look like actual events 

Using my code here:
~/Work/SLIMER/AnalysisCode/BackgroundAverage
Reduce the images to numpy arrays, and place them here:
/proj3/Slimer/Slimer_mk2/6_11_2013_mikes_ana

I'm also interested in plotting values as a function of time, or least as a function of the sequence.
I should plot a histogram of the pixel counts per image, as a function of image, as long as the images are ordered. 

Start writing some analysis code here:
~/Work/SLIMER/AnalysisCode/BackgroundStudy

The first thing to do is to calculate the means and standard deviations of each data set.
Do this by running:
~/Work/SLIMER/AnalysisCode/BackgroundStudy/background_averages.py

Which outputs:
For  with_lens_6_11_2013_90msec_image_array.npz  mean = 494.325271892  +/-  16.6281920055
For  no_camera2_6_11_2013_90msec_image_array.npz  mean = 493.885512532  +/-  15.983255603
For  no_source_6_11_2013_90msec_image_array.npz  mean = 494.132803889  +/-  17.5102654233
For  no_lens_6_11_2013_90msec_image_array.npz  mean = 494.39873512  +/-  17.7422307399
For  no_camera_6_11_2013_90msec_image_array.npz  mean = 493.991134101  +/-  17.2801490173
For  no_light_6_11_2013_90msec_image_array.npz  mean = 494.2603611  +/-  15.5165295105

Clearly, there appears to be no difference in the thermal noise. I should consider looking at the first and second moments 

Next up, plot the histograms of each dataset. The tails may be different between different data sets.
I've generated some plots using this script:
    ~/Work/SLIMER/AnalysisCode/BackgroundStudy/background_plot.py
which was used to generate the spectra in this PDF:
    /proj3/Slimer/Slimer_mk2/6_11_2013_mikes_ana/background_plot_output.df
The pages are not labeled, but they show the exact same spectrum. So there's no sign of a difference
in the tail between the various datasets.

I should try to plot the sources though, just to make sure I can see a difference there.
I may also want to nudge the axis of the histograms out past 800 to make sure there are no pixels with huge counts that could then get smeared out by gaussian smoothing.

Assuming that is not the case, an increase in single pixel spikes may be be excluded
So, the thermal mean, spread and tail don't appear to change between the runs.
However, distributed spikes as well as narrow ones may still contribute.

June 25th 2013 ---------------------------
Go ahead and run background_plot_output again, this time using wider axes to look for large amplitude pixels. 
Also include the source data as well. 

I can also plot the maximum pixel in each image for the various datasets. That should be easy. 
Wow. There are a good number of pixels above 1000 counts. The exponential tail may be just the pedestal.

Maximum value for 16bit integer is:
        65535
this is the largest pixel value we should see. 

Mary found the mean grey value to be around 510-530 counts, with a spread of roughly 10 counts or so. 
This is consistent with what we are seeing.

I've written 
    ~/Work/SLIMER/AnalysisCode/BackgroundStudy/summary_statistics_background_inspect.py
to look at the means, maxes, mins and STDS of the summary statistics of the data.
Here is the output:
For  with_lens_6_11_2013_90msec_image_array.npz
        126915490.0  <  imageSums  <  131934408.0   imageSums  =  129584404.075 +/- 642580.571585
        484.144172668  <  imageMeans  <  503.289825439   imageMeans  =  494.325271892 +/- 2.45125034937
        14.2513587371  <  imageSTDs  <  250.348696942   imageSTDs  =  14.8402789701 +/- 7.08902397438
        702.0  <  imageMaxes  <  65535.0   imageMaxes  =  962.207210626 +/- 2739.62641249
        8.0  <  imageHotPixels  <  2334.0   imageHotPixels  =  2163.93510436 +/- 161.667966129
For  cs137_6_11_2013_90msec_image_array.npz
        126774794.0  <  imageSums  <  131998273.0   imageSums  =  129463840.815 +/- 618587.497161
        483.607460022  <  imageMeans  <  503.53345108   imageMeans  =  493.865359553 +/- 2.35972403397
        14.2508105421  <  imageSTDs  <  205.384624051   imageSTDs  =  15.1666403246 +/- 9.01863443228
        688.0  <  imageMaxes  <  65535.0   imageMaxes  =  1108.82460137 +/- 3883.26414632
        10.0  <  imageHotPixels  <  2441.0   imageHotPixels  =  2199.18982536 +/- 213.214623644
For  no_camera2_6_11_2013_90msec_image_array.npz
        127151672.0  <  imageSums  <  131447612.0   imageSums  =  129469123.797 +/- 609546.317926
        485.045135498  <  imageMeans  <  501.432846069   imageMeans  =  493.885512532 +/- 2.32523467226
        13.5128387949  <  imageSTDs  <  244.673207387   imageSTDs  =  14.1719132506 +/- 7.01531311756
        688.0  <  imageMaxes  <  65535.0   imageMaxes  =  997.710198092 +/- 2952.33922059
        4.0  <  imageHotPixels  <  1710.0   imageHotPixels  =  1565.2325752 +/- 137.082739189
For  no_source_6_11_2013_90msec_image_array.npz
        127454129.0  <  imageSums  <  131631737.0   imageSums  =  129533949.743 +/- 609942.825006
        486.198917389  <  imageMeans  <  502.135227203   imageMeans  =  494.132803889 +/- 2.32674722674
        14.2750948375  <  imageSTDs  <  232.590609155   imageSTDs  =  14.9876637445 +/- 8.7501758906
        701.0  <  imageMaxes  <  65535.0   imageMaxes  =  984.318199016 +/- 3145.68775114
        12.0  <  imageHotPixels  <  2450.0   imageHotPixels  =  2209.38251986 +/- 162.278155881
For  no_lens_6_11_2013_90msec_image_array.npz
        127102892.0  <  imageSums  <  131612256.0   imageSums  =  129603662.019 +/- 612114.026318
        484.859054565  <  imageMeans  <  502.060913086   imageMeans  =  494.39873512 +/- 2.33502970245
        14.2532590737  <  imageSTDs  <  246.461033299   imageSTDs  =  15.0206592961 +/- 9.14954544455
        702.0  <  imageMaxes  <  65535.0   imageMaxes  =  1032.55462822 +/- 3477.94478414
        6.0  <  imageHotPixels  <  2336.0   imageHotPixels  =  2158.33877086 +/- 179.358476253
For  no_camera_6_11_2013_90msec_image_array.npz
        127110406.0  <  imageSums  <  131701571.0   imageSums  =  129496811.858 +/- 612977.322348
        484.887718201  <  imageMeans  <  502.401622772   imageMeans  =  493.991134101 +/- 2.33832291545
        13.5685855493  <  imageSTDs  <  192.575227729   imageSTDs  =  14.4970734516 +/- 9.10882304613
        695.0  <  imageMaxes  <  65535.0   imageMaxes  =  1154.93179951 +/- 4163.58203042
        8.0  <  imageHotPixels  <  1710.0   imageHotPixels  =  1578.50041085 +/- 163.899232149
For  bi207_6_11_2013_90msec_image_array.npz
        127084222.0  <  imageSums  <  131358876.0   imageSums  =  129560077.262 +/- 617985.792275
        484.787834167  <  imageMeans  <  501.094345093   imageMeans  =  494.232472466 +/- 2.35742871199
        14.4878725447  <  imageSTDs  <  205.327066126   imageSTDs  =  15.7535460707 +/- 9.76963909973
        698.0  <  imageMaxes  <  65535.0   imageMaxes  =  1238.93920973 +/- 4472.78337055
        9.0  <  imageHotPixels  <  2828.0   imageHotPixels  =  2469.06458967 +/- 286.584434199
For  no_light_6_11_2013_90msec_image_array.npz
        126949017.0  <  imageSums  <  131924005.0   imageSums  =  129567388.1 +/- 610598.200612
        484.272068024  <  imageMeans  <  503.250141144   imageMeans  =  494.2603611 +/- 2.32924728627
        14.2126337106  <  imageSTDs  <  130.085587209   imageSTDs  =  14.6745136458 +/- 4.47168255053
        702.0  <  imageMaxes  <  65535.0   imageMaxes  =  934.127942293 +/- 2379.22987306
        4.0  <  imageHotPixels  <  2319.0   imageHotPixels  =  2143.91609719 +/- 154.062859374


The only thing that seems to change is the number of hot pixels! Clear differences with the camera shutter closed on the low end, and 
the bi207 data on the high end. 

Findings:  mean pixels (the noise floor) don't seem to be effected,except by the temp setting. Makes sense: this is the thermal noise.
           The hottest pixel in an image is quite random, and the mean hottest pixel has a huge spread centered on ~ 1000. 
           The number of hot pixels (those 3 sigma above an average for each image) DOES vary when a source is present, and when the camera shutter is closed. 
           The mean does not vary much, so this is something to look at. 
June 26th 2013----------------------------------------------------------------------
Evidence that the pixel counts are not being processed correctly:
            When using background_plot.py, the histogram produced shows no pixels larger than 1,000 or so. Unless the problem is with the linear plot.
            When using summary_statistics_inspect.py, the average maximum pixel is shown to be ~1000, with a very large deviation?
            When using summary_statistics_plot.py, the histogram of imageMax clearly shows some images with pixel counts below 65535, but above 10,000. 
               
The distribution of hotpixels also is confusing: it looks like for all data sets, the number is >1000 most of the time? Gaussian statistics would expect 99% to be within 700....
It does look like most are >1000......I need to rethink my threshold.
For this, I need to look at the pixel count histograms. It looks like the pedestal doesn't go away until ~~~550 pixel counts, which is closer to 4 sigma away from the mean.
Use 5 as the threshold. run background_average on the images again. For these analysis runs, I've appended "_mk2" the resulting .npz files. 
It looks like the trend is still present: the no_lens data file has on average 555 +/- 55 hot pixels, while other sets have 770 +/- 70

Still confused about the pixel counts though.
I should try to replicate the computation of the max pixel counts again.


June 27th 2013-------------------------------------------------------------------------------------
Look into max pixel counts again. 
modify background_average.py into background_average_test.py to see what is going on.
First, display the output of amax(oneImageArray). Seeing large values above 1000 here will prove that my summary statistics analysis programs are not buggy.

I am already seeing the large max pixels show up. Okay. Now check to see if these pixels are actually present in the data.....
or if amax is somehow doing something funny.

I'm printing out pixel values in excess of 10,000, as well as the number. I'm also displaying amax(oneImageArray) when it is above 10,000.
Sometimes amax is displayed, but no associated pixel values are displayed. Something is behaving strangely.
It looks like comparing integer and decimal values can lead to problems. Comparing against integers appears to work.

Bottom line: there are some pixels with values above 10,000. Sometimes more than one in an image. 
Looks like I may have an histogram problem. 
Putting some code into background_plot_debug.py, I can see that these large pixels are still present in the data.
So I can focus on the histogram routine now. Limiting the plot to counts above 10,000 and with a linear y axis, I can clearly see
counts now. The problem: many bins =1, which would be zero in a logy plot.

So I need to clean up the histograms in general now. 

Looks like I am having problems with the Am241 run. After processing many files, it chokes and eats up memory.
During the first try, it chocked on am241_6_11_2013_90msect6886.tif

Try again, and count the number of files input first. 
The program has stalled again on am241_6_11_2013_90msect6886.tif after half an hour. This was file 7858.
Delete (or move) the file, and try again.
7857 /proj3/Slimer/Slimer_mk2/6_11_2013/am241_6_11_2013_90msec/am241_6_11_2013_90msect3561.tif
This is the last file in the bunch. The problem is AFTER the files are loaded.
The problem is during the computation of the STD.
Actually, even getting past that, I can't save the npz file since it is larger than 2GB, and npz files can't be larger than that. 
I'll need to switch over to using HDF5 format!


Once I've taken a look at the pixel counts past 1,000 and compared the different data sets, I can move on. 
I don't see much of a difference in terms of the shape of the tail past 100 pixel counts. 
Plot them all over on top of each other, perhaps with a log plot, and see if the AMPLITUDE of the tail is different. 
I don't see much of a difference, if any. 
----> only the # of hot pixels is a unique observable, it seems


July 8th 2013 -------------------------------------------------------
We've switched from using wit's standard python distribution to using Anaconda. This gives us newer code. 
The new version of numpy CAN write out npz files larger than 2GB now. This is good, since using PANDAS is tricky...
I think I would have needed to use a Panel, instead of series or DataFrame since I was trying to store a 3D ndarry. 

I'm still having issues with calculating the STD though. Could be a bug. The variance actually works. The only difference is a sqrt, and perhaps some 
array manipulations. I've run background_average on all the 6_11_2013 data sets, so this step should be done.

It looks like numpy has trouble using nunmpy.load on large arrays. This is fixed with a new numpy, but I don't think I want to mess with that. 
It should work with Python3 though, so I could switch.

Reexamine what I wish to do. 
             Compute a background average: this code works
             Compute summary statistics: this code works
             Quickly scan through many files: use parallel computing. 
Eventually I will want to be able to scan through many image files and look at images that pass certain cuts. 
For THAT I'll need some complicated HDF5 stuff, NOT pandas which aren't setup for this type of thing. 

I committed my existing code to git, and will now par things down. 

The existing averaged images are fine to use however.                

I could still use Pandas for other observables. I could record:
file name, including the whole path
the number of hot pixels
location of peak
peak height
peak area
and so on.

July 9th 2013----------------------------------------------------
I have some analysis code running for images now. The location is here:
    ~/Work/SLIMER/AnalysisCode/ImageAnalysis/image_analysis.py
this can input multiple images, and subtracts the background using a NPZ file. 
The background subtraction was a bit tricky, as the unsigned 16 bit integers in the array wrap around when the background is higher than the source pixel. 
I got around this by using a mask array. 

I need to code in a peak finder now. I should consider writing a seperate class for this, and need to select a technique. 
ndimage.measurements may be useful here
scikit-image may be useful as well

Cluster Analysis in general might be useful.
So might blob detection
watershed may work in a median or gaussian blur is applied.
k-means clustering(in scikits-learn, scipy, or openCV, or scipy-cluster)
Otsu's method
scikit-learn's linear support vector machine in kernel (radial basis function)smode

I'm seeing evidence of clustering, even with a threshold of 0.5 sigma. 

To implement a k-means approach, I'll need to integrate itensity data into the algorithm.
One way to do this is to feed the algorithm each point N times, where N is the pixel count

July 10th 2013 --------------------------------------------------
I've got a test k-means script running, and have also been able to apply it to images.
The key with the scipy implementation is to NOT whiten the data.

It looks like using k=2 works fairly well, one cluster will be the peak, and the other will be the background and thus junk, with wide seperations 
Using kmeans for images with 70 or more hot pixels that are at least 0.75 sigma above background seems to work. 
Applying it to ALL images seems to work: images with no clear cluster seem to product distortions of 100 or greater, and only 50% of pixels 
are in one cluster. The images with clusters seem to have distortions < 20, and 80% or more pixels are in a cluster. 

So this may work, when cuts are applied to the output of the kmeans algorithm. 

July 11th 2013---------------------------------------------------
It looks like my background average routine is choking again....the arrays are simply too large. 
Instead, I'll need to compute a running average and variance instead, as detailed here:
http://en.wikipedia.org/wiki/Algorithms_for_calculating_variance

def online_variance(data):
    n = 0
    mean = 0
    M2 = 0
 
    for x in data:
        n = n + 1
        delta = x - mean
        mean = mean + delta/n
        M2 = M2 + delta*(x - mean)
 
    variance = M2/(n - 1)
    return variance
Okay...the new background average has been implemented. 

The k-means algorithm when run on 241Am data, seems to do a pretty good job of finding clusters: there are far more points in one cluster, 
and the distortion is far lower (~30 instead of ~150).

On C14 data, the fraction is picking up clusters. The distortion is high though: 120 pixels. At least for some.
The efficiency is quite low as well. The good news is that the the algorithm is picking up fairly low energy events. I think.
A fraction of .39 still produces a very noticeable cluster

July 12th 2013 ----------------------------------------------------
I've coded a DBSCAN implementation, but the memory use is REALLY bad. I think I can code my own implemenation using the original image matrix, and have it run much faster.
Or I could run ELKI externally.

I've coded my own implemenation, commited a new git revision, and then started to take out the use of the scipy revision.
At this point, I'm going to have to debug the new dbscan code, and the code that uses it. Then I'll have to see if it works.

I also need to look at the two images that Erik sent me: I need to make sure they are not from a sharp spike.

July 15th 2013-----------------------------------------------------
DBSCAN is kind of working, but is slow. 
profiling now:
sum uses 144 total time
dbscan uses 371 total time, of which
regionQuery uses 221.577
numpy reduce uses 144
zeros uses 195

Stop using zeros in regionQuery
Profile again:
sum is using 121
dbscan uses 302 total time
regionQuery uses 176
sum is using 122
reduce uses 122 (could be same thing, or could be formation of the reduced sqaure matrix ) 

Stop using sums everywhere.

dbscan now uses 175 total time  
regionQuery uses 173 total time!

Indexing the array IS faster than applying bounds manually to a much larger matrix.
I think my logic has some issues: I need to be sure I only work with non-zero pixels in my code. Doing otherwise makes things very slow, and perhaps incorrect!

July 16th 2013----------------
Fixed a problem with array indices in queryRegion. Now code is slow again.
Cna profile python code using this command:
python -m cProfile

a 'sum' instance is using 2.725, and has been called 1300 times 
dbscan is using 172.472 per iteration. Of this,
expandCluster is using 157
regionQuery now uses 14.
iterNext uses 13.197

Fixed a few bugs.
now profile again:
348.444 dbscan
320.179 expandCluster
40.927 regionQuery

expandCluster was iterating through the whole 512x512 matrix. Only iterate through the non-zero neighborhood!
Profile again:
71.914 dbscan
43.127 expandCluster
38.620 regionQuery
2.299 distanceQuery
Not clear how to speed things up now. 

DBSCAN is now finding clusters, but it is not recording the members correctly: each cluster has only 1 pixel, even if that pixel is NOT large enough to form a cluster
fixed a problem with expandCluster.
Now getting multiple pixels, but now getting clusters with no pixels!!!!!!!!!!!! Also getting clusters with too few counts.
Zero cluster problem went away once I fixed some logic in expandCluster.

It seems that points are being removed from clusters after the fact: and points marked as being parts of clusters are being marked as noise later, or as members of other clusters.
So I've still got the logic wrong.

July 17th 2013 ------------
Core points should never be removed from a cluster. But edge points can: they can be memembers of more than one cluster
Corrected a problem with the dbscan method: I should only use points that haven't yet been visited.
This seems to help: points are no longer being moved from one cluster to another.

Now clusters have more than one pixel, have a count above MinPTS. So things look better now!

Need a good way to check the code now. Should code up the ability to compute the density of a cluster, and the percentage of counts in a cluster as well.

July 19th 2013---------------
Clean up dbscan code, then the entire analysis code, and then begin to run it on background
July 23rd 2013---------------
Continue code cleanup.
Things are now running. Commit and continue.

DBSCAN takes ALOT of time between when it announces the number of clusters found and picking the best.
This time is spent on "analyze_results" and is due to the computation of the cluster position.

I've changed the code to compute the covariance matrix, which isn't used just yet. 
A code tweak sped up the computation of the variance nicely.

Now circle back and code in the ability to actually extract and save parameters.
For now, just write out the cluster parameters and the file path to the image. I can look at parameters and the image using another program.
I will however need to code in an option look at which pixels are in which clusters.

July 29th 2013----------------------------------
ascii and hdf5 output now work! Code committed!

It seems like something is trying to make an X connection however. That is NOT right!
It is okay....it is matplotlib.

July 31st 2013 -------------------------------
Found a problem with the threshold setting: I was multiplying the threshold in sigma by the variance, NOT the sigma
I'm seeing events with DBSCAN clusters < minPts. This implies a bug.
I've tweaked the DBSCAN requirements, and this seems to reject background more effectively.
However, the code runs MUCH longer now. 
Time to do some more profiling.....
regionQuery is eating up most of the time.
Of this, roughly a third is spent with distanceQuery.
Not much to do now.....

Aug 5th 2013 ------------------------------
I'll need to change the output code in case DBSCAN finds no clusters. 
For now, continue to add to the output code.
Aug 6th 2013 ------------------------------
Erik is seeing a difference in energy scale between different magnifications (10x and 20x).
The objectives that we have are:
CFI Pan Flour    MRH 00401   40xa   NA 0.75  WD 0.72
                 MRH 00201   20xa   NA 0.50  WD 2.1
                 MRH 00041   4xa    NA 0.13  WD 17.2
                 MRH 00101   10xa   NA 0.30  WD 16    
                 
Newport has a nice explaination of NA and general optics here:
http://www.newport.com/Tutorial-Light-Collection-and-Systems-Throughput/381845/1033/content.aspx

In the above, they relate flux (phi_c) to the F-number:
    phi_c approx 1/(F-number^2)
However the Numerical Aperture (NA) = 1/(2F-number)

so phi_c approx (2*NA)^2
So 10x -> 20x should produce (0.50/0.30)^2 = 2.78 more light! 

Aug 7th 2013 ------------------------------
slimer_ana is now done. Clean things up and think about what else is needed....
The only parallel part of the analyis chain is image_analysis. 
So I need to write:
    bash scripts for running background_average.py on specific datasets
    SGE scripts for running image_analysis.py on arbitrary datasets across the cluster
        a bash script for running image_analysis.py on a specific subset of data
    a bash script which runs the SGE script on specific datasets.
    a tool with which to sum multiple hdf5 files
    a bash script to run slimer_ana.py on a specific dataset.
    
The HDF5 summing tool is now written. 

Now write scripts.
I have a script ready to run image_analysis. I need to debug it. 


Find some data:
    /proj/Slimer/Slimer_mk2/8_01_2013/
write a script to do the background average:
    /proj/Slimer/Slimer_mk2/8_01_2013_mikes_ana/scripts/

background_average is disk, not CPU, bound. Implies should always be run on node3, and perhaps on local_scratch.
    Here was the output of that job:
    Number of Images: 10641
[[ 500.16398835  500.33239357  500.69702096 ...,  500.36152617
   503.47213608  503.08890142]
 [ 500.69523541  500.74570059  500.69702096 ...,  500.50765905
   502.88873226  502.63565454]
 [ 500.67249319  500.50089277  500.77145005 ...,  500.6090593   503.20740532
   502.64138709]
 ..., 
 [ 503.11728221  502.97190114  503.10064844 ...,  502.89239733
   505.58340382  505.10074241]
 [ 503.28991636  502.91701908  503.32609717 ...,  503.19641011  505.3452683
   505.42326849]
 [ 503.15026783  503.26567052  503.32027065 ...,  502.83168875
   505.49769758  505.26125364]] [[  90.29913913  142.25839511  220.79108981 ...,  123.63084669
   150.34793124  143.65638151]
 [ 144.07449703  139.51352122  134.81684169 ...,  149.93041596
   163.70453562  131.73650683]
 [ 144.41406379  132.83404526  156.7528352  ...,  131.96369236  157.2606444
   141.45014409]
 ..., 
 [ 174.73530374  128.54610888  126.51684262 ...,  153.4501687   165.95547266
   153.83063949]
 [ 135.2303203   157.43907217  215.51977846 ...,  147.23679538
   143.48641769  137.59413522]
 [ 153.59668437  240.25413059  897.17128925 ...,  158.69074761
   161.00189789  154.90711606]]

    
I now have other scripts in:
    /proj/Slimer/Slimer_mk2/8_01_2013_mikes_ana/scripts/    

now everything is pretty much working!    
    It DOES look lime hdf5_sum isn't working correctly: only one event is present. Or slimer_ana may be messed up.
    

Aug 8th 2013 -------------------------------------------------
It looks like the variance between pixels in the 8_01_2013 dataset is quite large!!!!!!!!!!!!!!!!!
does this make sense?????

Back to the analysis chain first. the summed HDF5 file seems to have 105 entries, so that part of the code should be working.
The problem seems to be in slimer_ana, namely the cut stage.

No, the problem is that ALL images are failing the DBSCan found clusters cut.
image_analysis IS finding "hot pixels", and many of them.
It looks like the problem is with DBSCAN.
Tweak minPts and eps from 1000 and 5.0 to 200 and 5.0.
Now I'm getting MANY clusters.
use 500 and 5.0.....now some clusters are found.

slimer_ana is now working .... kind of. 

Automatic histogram axis computation is NOT working in slimer_ana. Actually, it IS. there are some large outliers in the data.

Computation of the cluster position is NOT working all the time in image_analysis. There was a problem with the weighted mean calculation.
It has been fixed.

Aug 9th 2013 --------------------------------------------
We now have a new tool for nd2 --> tiff conversion. It is a library called Bio-Formats.
The command line tools are written in java, and conversion from the head node is SLOOOOW when reading and writing over NFS. 
I've installed icedtea java on all worker nodes to allow this tool to be run from node3, so NFS is not used. 
Now it is FAST....much more so than using the SLIMER DAQ machine. 

We want to compress the data down to monochrome, so the proper command is:
/proj/Software/ImageProcessing/bftools/bfconvert <path to nd2 file> <root_name>_%t.tiff

which will split the frames in the nd2 files, and append labels based on frame number

using <root_name>_%A.tiff instead will result in file stamps according to exposure time.
HOWEVER THE USE OF THE %A STAMP WILL ONLY GO DOWN TO THE SECOND, SO IMAGES WILL BE SUMMED INTO GROUPS OF SECONDS.

For full seperation, we'll need to use the %t tag.

Other information on bftools can be found here:
http://www.farsight-toolkit.org/wiki/FARSIGHT_Tutorials/Bio-Formats

Aug 10th 2013 ---------------------------------------------
Syncing git repos.
to update things FROM another repo (from say wit):
    git pull ronquest@wit.lanl.gov:/home/ronquest/Work/SLIMER <name of branch>
to push the updates back to the remote server (useful for when a pull FROM the remote server is not possible) do:
    git push ronquest@wit.lanl.gov:/home/ronquest/Work/SLIMER <name of branch>
note that one cannot push to a branch which is already checked out ON THE SERVER.
The way around this is to work on different branches between the serve and client.

So, form this point forward, I will leave the master branch alone, and develop in the branch mike_working.
Anyone who wants to collaborate should create their own repo, and THEN their own branch. And then push that branch to the server.
Note that they may need to create the branch on the server FIRST. 


Getting USB drive resets from the SLIMER drive when connected to wit. Need to find a place where this does NOT happen.

Looks like I finished analysis on no_source_8_01_2013_200msec.
What time spreads are present in the files? It looks like it takes about two hours to process everything. 
Running hdf5 sum......
Looks like I've got 10632 images......
....and 223 pass my cuts, with clustering set to MinPts=500/eps=5.0 (pixel density of ~ 6.41). 2% leakage. 
130 of these events have an average pixel count of les than 30 counts. 
Most pixels have < 1000 counts, and there is a spike at 500 counts!. On average, there are 27 pixels in a cluster.
On average the maximum peak height is 160 counts.

Aug 12th 2013 ----------------------------------------------
The bioformats tools bfconvert and showinfo have a memory limit wired into the scripts as an argument to java. 
I've copied them, and changed the memory limit to 5GB.
This appears to have worked. 

I've tarred up Mary's old files in Slimer_mk1. This will buy us some more space.

I'm transferring the nd2 files into Slimer_mk2/nd2_storage/

I'm running bfconvert_large on the c14 data from Aug 9th.
I'm doing the same to the background runs from the 8th and 9th.
In order to process the 10 hour background run, I'll need bump up the memory on bfconvert, again.
Try 15GB. That does not work either. 
I may need memory equal in size to the nd2 file!    Look at bfconvert again to see if I have options for partial conversion....
It looks like I do NOT. The entire nd2 file is loaded into memory it seems before any slices are processed. 
Since the newer worker nodes have 19GB of RAM and 37GB of swap....I could take things up to 56GB. But 20GB seems safer. 
That implies we could take data for a bit over two hours. 
Wait. the "%s" flag DOES work, and produces a large, but not as large tiff file if the -bigtiff tag is used.
Does %A work? YES. 
try again with %t. It works! 
The key is the -bigtiff tag! 
Next question: why are there only 12907 frames?????
run with the %A tag again, and see if that produces more frames.
With a ten hour run, there should be 36,000 frames. There are not. There are only 4385 frames: a bit more than an hour???!!!!

Tomorrow, I need to see if I can find any exports from Elements......does it extract a different number of frames, or extract 
from a different range of times?

Aug 13th 2013-------------------------------------------------
It appears that Elements does indeed export many more slices (up past 30,000) than bfconvert does. 
However, this is not a big deal, as we've figured out how to split things up into one hour runs. 

I strongly believe that I was converting the smaller background file rather than the large one last night, so the large background file
is still not useable. 

Run analysis again. Set minPts =175.0 eps=2.0 (25 pixels)
This really pumps up the background rate....

Go in the opposite direction:  Try 300.0, eps=2.0 
Still not much of an improvement. Try 700.0, eps=2.0
    ---> out of 2208 images, 35 have clusters
    --->  954 images, 12 have clusters. 
Aug 14th 2013------------------------------------------------
using bzip2 on nd2 files shrinks them to roughly 40% of their original size. Once they are converted, they should be bzipped
Lzma takes much longer, but does not result in a smaller filesize.


Aug 18th 2013-------------------------------------------------
Updated git repos between wit and my laptop.

Aug 19th 2013-------------------------------------------------
Run analysis on the background samples again. 
It appears as though the sample with the camera shutter closed as a SMALLER exponential tail than the other datasets. This implies
there is a light leak. I'll want to produce an overlay plot and ratio plot to illustrate this.

The data from 6_11 and 7_01 look quite different. 7_01 has a higher modial value, but a smaller width in the gaussian and a smaller and steeper exponential tail.
The 6_11 shows a jump from no_camera to no_lens, while the 7_01 data shows a jump from
no_camera to no_microscope.  

I'll need to try to find this light leak.....but plot the result of opening the camera shutter first. 

Aug 20th 2013 ------------------------------------------------
Collected a new light leak data set. Also found a leak in the door as well and tried to cover it up.
But first, I need to make room and reorganize the directories.
I've moved Eriks code and files to a few directories in Slimer_mk2
Now compress all tiff files into tarballs to save space.  

New procedure: nd2 files stay on /proj3, while the extracted tiffs go to 
/bigscratch4/ronquest/SLIMER/converted_data

I've already converted the data collected yesterday and today over to the above location.
I'm running the background_analysis.pyscript on these data now.
It appears that the tail for the light leak runs is the same...until I attempeted to close the drop cloth over the box, 
and until I closed the camera shutter.
At 542 counts:
wide open: 31530 events
hold_shut: 18929 events   --> 40% reduction from wide open
camera closed: 12732 events --> 60% reduction from wide open.
Working on the door is a clear prioroty. Seal the crap out of it and see if the tail can be reduced to the level of the 
camera shutter closed.


I'll need to move the 8_09_2013 directory to local_scratch for compression....
Once that is done, I'll have enough space to generate the tarballs for everything else.

Aug 22nd 2013 -----------------------------------------------------------------------
Compression of data should be complete. 
Next step is to check to see which datasets as also in .nd2 format
Copy the 8_09_2013 directory back to /proj3. Done. 
Now begin to delete the tiff files to make room on /proj3. I've got 170GB free, so can stop for now. 
/local_scratch/ronquest cleaned up.

I still need to clean up /local_scratch/super
and slimer_data.

Still working on fusing Erik's code with my own. Just have to work out how and what to output and store.
May also want to code ability to find multiple clusters for the analysis code: better efficiency and 
more compatible with observing multiple decays in a Phylochip

Aug 30th 2013 -------------------------------------------------------------------
I'll need to change things so that I write output after each image processed. The hdf5 file is in table mode, so I should be able to append it.
I've coped dbscan_analysis.py to dbscan_analysis.py_old: I'll need this code as I'll be forced to rip out the best cluster code
Actually, I don't need to remove the code, just not use it. 

Sep. 3rd 2013 -------------------------------------------------------
I just took more light leak data. Analyze it.
The files are:
door_taped_9_3_2013_200msec
shutter_open_9_3_2013_200msec
shutter_closed_9_3_2013_200msec

the nd2 files are in nd2_storage, while the converted tiffs are on 
/bigscratch4/ronquest/SLIMER/converted_data/

The pixel count distribution is NOT appreciably different with the camera shutter open and the door taped. 
It IS still different with the shutter closed. 
However, I left the light on. Power that down, and the stage, and take more data.

After sticking my head into the darkbox and taking a good look around, I've found an LED on the hub controller. Power that down shuts the light off.
I've taken more data, and the files are:
light_and_stage_on_scope_off_9_3_2013_200msec.nd2
scope_off_9_3_2013_200msec.nd2
door_taped_2_9_3_2013_200msec.nd2
light_and_stage_off_9_3_2013_200msec.nd2

---->RUNNING WITH THE SCOPE OFF RESULTS IN NEARLY THE SAME PIXEL COUNT DISTRIBUTION AS RUNNING WITH THE CAMERA SHUTTER CLOSED<--------------------
---->WHEN THE SCOPE IS OFF, THE LIGHT AND STAGE POWER HAVE NO EFFECT. <---------------------------------------------------------------------------
---->NOTE THAT THE CAMERA HAS A FLASHING LED WHEN THE SHUTTER IS CLOSED. SO SHUTTER CLOSED RUNS STILL MAY NOT BE THE BEST <-----------------------
---->I MAY BE SEEING EVIDENCE OF MORE OUTLIER EVENTS WITH DIFFERENT RUNS. THIS IS DIFFERENT THAT THE EXPONENTIAL TAIL I'VE BEEN FIGHTING. THESE ARE EVENTS WITH MORE THAN 700 COUNTS<--------

light and stage power don't seem to matter when the hub is on as well.

I've made a nice plot of the situation here:
/home/ronquest/Work/SLIMER/AnalysisCode/BackgroundStudy/lightLeak_overlay_09_03_2013_hub_smoking_gun.pdf

Sep. 6th 2013 ----------------------------------------------------------
Continuing to overhaul the output code. I've removed the ASCII code since I can always simply convert the HDF5 tables into ASCII format.
I will try to output the data into seperate HDF5 files in the same store. This enables me to avoid padding. 
Each analysis method will get its own table, and the file name of the image will be the index.
Commit the code as is and implement this new approach.

I'll need to modify the hdf5 sum code to handle this as well.  

I think I'm bumping into a problem with Erik's fitting code: in shaw_fit.py,  the method optimize.leastsq(errorfunction, moment)
I should take a close look at the values of errorfunction: it could be doing something nasty

Sep 8th 2013 ------------------------------------------------------------
Modifications to image_analysis.py are complete. I'm still having issues with Erik's fitting code, so I've disabled it for now. His cluster code DOES work though.
However, the output code does NOT. It works fine as long as each variable is a single value, but multiple element arrays are crashing the HDF5 code. I don't think
this is specific to shawcluster: the problem goes away if an index is not used. I may need an index per element. I do.
I need to check to see if using the same index in multiple rows would cause a problem. I don't think it will

Sep 9th 2013 -----------------------------------------------------------
I've taken data with various cables unplugged from the hub.
The data files are:
cables_in_9_9_2013_200msec.nd2
cables_out_9_9_2013_200msec.nd2
hub_off_9_9_2013_200msec.nd2
shutter_closed_9_9_2013_200msec.nd2
stage_in_9_9_2013_200msec001.nd2
stage_out_9_9_2013_200msec.nd2

I've converted and run analysis on the above. Two groups are formed:
high tail:
    cables_in_9_9_2013_200msec.nd2
    stage_in_9_9_2013_200msec001.nd2
    
    
low tail:
    cables_out_9_9_2013_200msec.nd2
    hub_off_9_9_2013_200msec.nd2
    shutter_closed_9_9_2013_200msec.nd2
    stage_out_9_9_2013_200msec.nd2

So the problem occurs when the stage is powered up!
It has "encoders" which are likely optical encoders. 
Two approaches: a usb or ethernet switch that can be used to power the hub on and off
Or use a filter cube that filters light of this wavelength.

It wasn't the stage that the cable powered, it was the filter wheel! The stage has no encoder. 
The filter turret is a TI-FLC-E.

I should run with both filter cubes to see if they can cut ALL the ambient light.
Run with:
no filter
one filter
the other filter
with the turret unplugged. 

Note that running with a filter will cut the CsI light..... 
Sept 10th 2013--------------------------------
Don't use the image name as the index for the other dataframes. This may create problems later.
Go ahead and DO use the index for General_ImageData 






 













data set          mean      std      median   mode   
----------------------------------------------------








I've looked at the 241Am source data from 8_01. I see very little difference compared to the background data, except the
rate of detection is much higher (For the 214Am data, there are 2797 images with clusters, out of 10064) 
So right now, with the current cluster settings, I get clusters of the same characteristics as the background, but at a different rate. 
This is the same thing that Erik was seeing. Crap.

Fix the hot pixel calculation first.



I'll need to make sure that the different runs are not different lengths clock-wise. It is possible that CsI scintillation events are causing triggers, but that the pre-clearing stuff 
is being run and that the exposure is not taken until after the scintillation light is gone.




If there is low level contamination, it may be interesting to compare a run with and without the CsI.
These files already exist however.....




  




















 
	




===========================
Check to make sure bfconvert is getting all exposures.


Study pixel to pixel variances. 

I will however need to code in an option look at which pixels are in which clusters.
I should be able to find the "good cluster" by averging the distance for all points, and picking the one with the smaller average distance. 




I should check to make sure that events that appear to be real events don't also have more hit pixels in the background as well. 


The next step is to PLOT the images, setting pixels less than say 3,4,or 5 sigma equal to zero, and setting the other pixels to maximum amplitude.
Do this for all datasets in order to look at the distribution of hot pixels. 
I want to see if the hot pixels are clustered in any way.


Given the hot pixel observation, I should take some more data with the camera shutter closed, by:
having the box open
having the box closed (we've done with before)
having the box closed and covered
having the box closed and covered, and the lights off downstairs (need to cover screen, and use delay in data taking)      
      
      
      
      
                  
            
           
           
            




























 





 









