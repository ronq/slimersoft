May 28th 2013 ---------------------
Begin work on SLIMER. 

Image manipulation using python:
See
http://pythonvision.org/software

http://www.itk.org/

http://www.cellprofiler.org/

http://opencv.willowgarage.com/documentation/python/cookbook.html

http://scipy-lectures.github.io/advanced/image_processing/

http://scikit-image.org/

Also, don't forget about ImageMagick, which has python bindings.

http://code.google.com/p/priithon/

May 30th 2013 ---------------------------
Had a chat with Mary via phone today. Here are the Q&A:
1) procedure for centering scintillator?
There is a button down and to the right--turn on light. This will shine through the 
objective. Should try to focus this light down to ease alignment.  
The spot light is about the same as a source, but cover camera just in case.  


2) special handling precautions for scintillator? Has coating, don't touch base 
(top yellow portion). White on edges is oxidation. Glass side is bottom. 

3) Light settings when running? Is the box switched completely off? Switched off light.

4) Confirm temperature dependence setting? Readout noise may be temperature dependent. 
So it is a battle between readout noise and thermal noise. 
Thermal noise is a constant noise throughout all pixels: not "spikey" 


5) Camera calibration? How to do? Turn on camera, attachment ring turns to close shutter,
orange light comes on, and this activates the RapidCal, and takes a few minutes.
Once light turns green, it is done. Sometimes never turns to green.
In this case, repeat. Camera has to be fully cooled. May have to be set to coldest setting.

6) Had issues with filter wheels? Don't recall......Filters should help, not hurt.
Could see 241Am and 90Sr signals with filters. These are the SEMROCK filters. 
Their efficiency is quite high.

7) Readout speed used? 1 Mhz --> use slowest.

8) With the Ti-U, can't do z position with stage? How to focus?
Nope. Must manually focus (see below). 

9) Focus procedure? Manual? Look at edge of scintillator, can see fiber optic 
Use light for this, need to adjust down to low light levels. Use Live View 
in video mode. 

10) worry about objectives hitting the motorized stage?
Biggest objective would get really close to sample. biggest is 40X
Be careful. 


11) any mounts for holder on stage? Or just put scintillator on top?
Clamp scintillator on holder---should fit. 

12) SLIMER data on external rugged disk? Safe to wipe clean?
May have uploaded everything to WIT before, but can't recall.
Check first.
 
13) Manual for Nikon NIS Elements? There is one on the computer. 
It may be on the anti-priracy thumb drive.

14) Any other hints?

15) Your best idea of problems?

16) Anything hard to reproduce? No. 241Am plots could be reproduced consistenly. 

17) Anything special about nd2 file format? 
Maybe not. Maybe only way to take movies. 

18) Any solutions/thoughts about dynamic range issues?
Have a bunch of grey scale available on camera, everything is crowded
down by 300. Camera guys thought she was crazy when brought up. 
Nothing would really blow out a pixel. 
Normally played with gain of camera and total number of possible grey scale numbers. 
2^32. Never really helped. 
Noise is around grey value of 300....

19) Will need to chat again next week!!!!!!!!!!!

20) power input for firewire cable? Problems with board?
Microscope guy was missing a bracket to hold it still.
Should get bracket. 
But always worked. Cover was loose so bracket could be installed later. 
No idea about power.

21) What is the "1/3" next to gain setting?
This is the fractional gain thing. Couldn't see a difference.
Maybe gain without E/M on. 

22) What are LUTS? It is a noise histogram: number of pixels at a certain value. 
But not sure.  
 
23) Worry about exposing camera to ambient light? While on?
Never seemed to hurt it. Try not to shine light directly onto it.

24) No filters should be in place, correct? Filters don't help signals.
Filter is tuned to CsI output. Second? Look for empty boxes to find out what the second
was tuned to.

25) Always start with lowest power.....if not far enough back you may miss activity
Start with 4x. Only use 40x when everything is fine tuned. 
This is more a function of activity area. 
Objectives are manual. 
 
26) Mode setting is all on software. Needed to use EM mode and high gain (250)
to see 241Am. Readout noise is much worse in EM mode though. 

Other notes:
Mary thought that we had proof of principle in that we had some signals from radiation.
Cs137 and 90Sr --> clearly seeing signals, just couldn't get down to carbon 14 energies.

Different readout modes: BERT, some noise problems, including readout noise.
Noise obscures the C14. 
Maybe all readout noise? 
Camera was roughly $30k. 

May have seen the 59 keV x-ray from Am241, using a source that was encapsulated.
This was in the form of the shoulder 
C14 endpoint is 156 keV:

Noise is randomly distributed and is single pixel spikes: turning up readout rate,
this increases.

June 24th 2013 ----------------------------
Time to look at backgrounds. A few days ago, we took different data sets in order to study backgrounds. 
These data can be found here:
/proj3/Slimer/Slimer_mk2/6_11_2013

they are:
am241_6_11_2013_90msec --> data using am241
bi207_6_11_2013_90msec001 --> data using bi207
cs137_6_11_2013_90msec --> data using cs137
no_camera2_6_11_2013_90msec --> second run with camera shutter closed
no_camera_6_11_2013_90msec --> first run with camera shutter closed
no_lens_6_11_2013_90msec002 --> run with a blank lens selected, but with the camera shutter open
no_light_6_11_2013_90msec --> can't recall
no_source_6_11_2013_90msec001 --> run with an objective lense selected, and the CsI in place
with_lens_6_11_2013_90msec---> run with an objective lens selected, but no CsI in place

I'm interested in the background levels. There should be two, maybe three kinds of background:
1) random thermal noise--> shows up as a baseline for all pixels
2) readout noise --> shows up as single pixel "spikes"
3) fake hits --> large, distributed hits of many pixels, which look like actual events 

Using my code here:
~/Work/SLIMER/AnalysisCode/BackgroundAverage
Reduce the images to numpy arrays, and place them here:
/proj3/Slimer/Slimer_mk2/6_11_2013_mikes_ana

I'm also interested in plotting values as a function of time, or least as a function of the sequence.
I should plot a histogram of the pixel counts per image, as a function of image, as long as the images are ordered. 

Start writing some analysis code here:
~/Work/SLIMER/AnalysisCode/BackgroundStudy

The first thing to do is to calculate the means and standard deviations of each data set.
Do this by running:
~/Work/SLIMER/AnalysisCode/BackgroundStudy/background_averages.py

Which outputs:
For  with_lens_6_11_2013_90msec_image_array.npz  mean = 494.325271892  +/-  16.6281920055
For  no_camera2_6_11_2013_90msec_image_array.npz  mean = 493.885512532  +/-  15.983255603
For  no_source_6_11_2013_90msec_image_array.npz  mean = 494.132803889  +/-  17.5102654233
For  no_lens_6_11_2013_90msec_image_array.npz  mean = 494.39873512  +/-  17.7422307399
For  no_camera_6_11_2013_90msec_image_array.npz  mean = 493.991134101  +/-  17.2801490173
For  no_light_6_11_2013_90msec_image_array.npz  mean = 494.2603611  +/-  15.5165295105

Clearly, there appears to be no difference in the thermal noise. I should consider looking at the first and second moments 

Next up, plot the histograms of each dataset. The tails may be different between different data sets.
I've generated some plots using this script:
    ~/Work/SLIMER/AnalysisCode/BackgroundStudy/background_plot.py
which was used to generate the spectra in this PDF:
    /proj3/Slimer/Slimer_mk2/6_11_2013_mikes_ana/background_plot_output.df
The pages are not labeled, but they show the exact same spectrum. So there's no sign of a difference
in the tail between the various datasets.

I should try to plot the sources though, just to make sure I can see a difference there.
I may also want to nudge the axis of the histograms out past 800 to make sure there are no pixels with huge counts that could then get smeared out by gaussian smoothing.

Assuming that is not the case, an increase in single pixel spikes may be be excluded
So, the thermal mean, spread and tail don't appear to change between the runs.
However, distributed spikes as well as narrow ones may still contribute.

June 25th 2013 ---------------------------
Go ahead and run background_plot_output again, this time using wider axes to look for large amplitude pixels. 
Also include the source data as well. 

I can also plot the maximum pixel in each image for the various datasets. That should be easy. 
Wow. There are a good number of pixels above 1000 counts. The exponential tail may be just the pedestal.

Maximum value for 16bit integer is:
        65535
this is the largest pixel value we should see. 

Mary found the mean grey value to be around 510-530 counts, with a spread of roughly 10 counts or so. 
This is consistent with what we are seeing.

I've written 
    ~/Work/SLIMER/AnalysisCode/BackgroundStudy/summary_statistics_background_inspect.py
to look at the means, maxes, mins and STDS of the summary statistics of the data.
Here is the output:
For  with_lens_6_11_2013_90msec_image_array.npz
        126915490.0  <  imageSums  <  131934408.0   imageSums  =  129584404.075 +/- 642580.571585
        484.144172668  <  imageMeans  <  503.289825439   imageMeans  =  494.325271892 +/- 2.45125034937
        14.2513587371  <  imageSTDs  <  250.348696942   imageSTDs  =  14.8402789701 +/- 7.08902397438
        702.0  <  imageMaxes  <  65535.0   imageMaxes  =  962.207210626 +/- 2739.62641249
        8.0  <  imageHotPixels  <  2334.0   imageHotPixels  =  2163.93510436 +/- 161.667966129
For  cs137_6_11_2013_90msec_image_array.npz
        126774794.0  <  imageSums  <  131998273.0   imageSums  =  129463840.815 +/- 618587.497161
        483.607460022  <  imageMeans  <  503.53345108   imageMeans  =  493.865359553 +/- 2.35972403397
        14.2508105421  <  imageSTDs  <  205.384624051   imageSTDs  =  15.1666403246 +/- 9.01863443228
        688.0  <  imageMaxes  <  65535.0   imageMaxes  =  1108.82460137 +/- 3883.26414632
        10.0  <  imageHotPixels  <  2441.0   imageHotPixels  =  2199.18982536 +/- 213.214623644
For  no_camera2_6_11_2013_90msec_image_array.npz
        127151672.0  <  imageSums  <  131447612.0   imageSums  =  129469123.797 +/- 609546.317926
        485.045135498  <  imageMeans  <  501.432846069   imageMeans  =  493.885512532 +/- 2.32523467226
        13.5128387949  <  imageSTDs  <  244.673207387   imageSTDs  =  14.1719132506 +/- 7.01531311756
        688.0  <  imageMaxes  <  65535.0   imageMaxes  =  997.710198092 +/- 2952.33922059
        4.0  <  imageHotPixels  <  1710.0   imageHotPixels  =  1565.2325752 +/- 137.082739189
For  no_source_6_11_2013_90msec_image_array.npz
        127454129.0  <  imageSums  <  131631737.0   imageSums  =  129533949.743 +/- 609942.825006
        486.198917389  <  imageMeans  <  502.135227203   imageMeans  =  494.132803889 +/- 2.32674722674
        14.2750948375  <  imageSTDs  <  232.590609155   imageSTDs  =  14.9876637445 +/- 8.7501758906
        701.0  <  imageMaxes  <  65535.0   imageMaxes  =  984.318199016 +/- 3145.68775114
        12.0  <  imageHotPixels  <  2450.0   imageHotPixels  =  2209.38251986 +/- 162.278155881
For  no_lens_6_11_2013_90msec_image_array.npz
        127102892.0  <  imageSums  <  131612256.0   imageSums  =  129603662.019 +/- 612114.026318
        484.859054565  <  imageMeans  <  502.060913086   imageMeans  =  494.39873512 +/- 2.33502970245
        14.2532590737  <  imageSTDs  <  246.461033299   imageSTDs  =  15.0206592961 +/- 9.14954544455
        702.0  <  imageMaxes  <  65535.0   imageMaxes  =  1032.55462822 +/- 3477.94478414
        6.0  <  imageHotPixels  <  2336.0   imageHotPixels  =  2158.33877086 +/- 179.358476253
For  no_camera_6_11_2013_90msec_image_array.npz
        127110406.0  <  imageSums  <  131701571.0   imageSums  =  129496811.858 +/- 612977.322348
        484.887718201  <  imageMeans  <  502.401622772   imageMeans  =  493.991134101 +/- 2.33832291545
        13.5685855493  <  imageSTDs  <  192.575227729   imageSTDs  =  14.4970734516 +/- 9.10882304613
        695.0  <  imageMaxes  <  65535.0   imageMaxes  =  1154.93179951 +/- 4163.58203042
        8.0  <  imageHotPixels  <  1710.0   imageHotPixels  =  1578.50041085 +/- 163.899232149
For  bi207_6_11_2013_90msec_image_array.npz
        127084222.0  <  imageSums  <  131358876.0   imageSums  =  129560077.262 +/- 617985.792275
        484.787834167  <  imageMeans  <  501.094345093   imageMeans  =  494.232472466 +/- 2.35742871199
        14.4878725447  <  imageSTDs  <  205.327066126   imageSTDs  =  15.7535460707 +/- 9.76963909973
        698.0  <  imageMaxes  <  65535.0   imageMaxes  =  1238.93920973 +/- 4472.78337055
        9.0  <  imageHotPixels  <  2828.0   imageHotPixels  =  2469.06458967 +/- 286.584434199
For  no_light_6_11_2013_90msec_image_array.npz
        126949017.0  <  imageSums  <  131924005.0   imageSums  =  129567388.1 +/- 610598.200612
        484.272068024  <  imageMeans  <  503.250141144   imageMeans  =  494.2603611 +/- 2.32924728627
        14.2126337106  <  imageSTDs  <  130.085587209   imageSTDs  =  14.6745136458 +/- 4.47168255053
        702.0  <  imageMaxes  <  65535.0   imageMaxes  =  934.127942293 +/- 2379.22987306
        4.0  <  imageHotPixels  <  2319.0   imageHotPixels  =  2143.91609719 +/- 154.062859374


The only thing that seems to change is the number of hot pixels! Clear differences with the camera shutter closed on the low end, and 
the bi207 data on the high end. 

Findings:  mean pixels (the noise floor) don't seem to be effected,except by the temp setting. Makes sense: this is the thermal noise.
           The hottest pixel in an image is quite random, and the mean hottest pixel has a huge spread centered on ~ 1000. 
           The number of hot pixels (those 3 sigma above an average for each image) DOES vary when a source is present, and when the camera shutter is closed. 
           The mean does not vary much, so this is something to look at. 
June 26th 2013----------------------------------------------------------------------
Evidence that the pixel counts are not being processed correctly:
            When using background_plot.py, the histogram produced shows no pixels larger than 1,000 or so. Unless the problem is with the linear plot.
            When using summary_statistics_inspect.py, the average maximum pixel is shown to be ~1000, with a very large deviation?
            When using summary_statistics_plot.py, the histogram of imageMax clearly shows some images with pixel counts below 65535, but above 10,000. 
               
The distribution of hotpixels also is confusing: it looks like for all data sets, the number is >1000 most of the time? Gaussian statistics would expect 99% to be within 700....
It does look like most are >1000......I need to rethink my threshold.
For this, I need to look at the pixel count histograms. It looks like the pedestal doesn't go away until ~~~550 pixel counts, which is closer to 4 sigma away from the mean.
Use 5 as the threshold. run background_average on the images again. For these analysis runs, I've appended "_mk2" the resulting .npz files. 
It looks like the trend is still present: the no_lens data file has on average 555 +/- 55 hot pixels, while other sets have 770 +/- 70

Still confused about the pixel counts though.
I should try to replicate the computation of the max pixel counts again.


June 27th 2013-------------------------------------------------------------------------------------
Look into max pixel counts again. 
modify background_average.py into background_average_test.py to see what is going on.
First, display the output of amax(oneImageArray). Seeing large values above 1000 here will prove that my summary statistics analysis programs are not buggy.

I am already seeing the large max pixels show up. Okay. Now check to see if these pixels are actually present in the data.....
or if amax is somehow doing something funny.

I'm printing out pixel values in excess of 10,000, as well as the number. I'm also displaying amax(oneImageArray) when it is above 10,000.
Sometimes amax is displayed, but no associated pixel values are displayed. Something is behaving strangely.
It looks like comparing integer and decimal values can lead to problems. Comparing against integers appears to work.

Bottom line: there are some pixels with values above 10,000. Sometimes more than one in an image. 
Looks like I may have an histogram problem. 
Putting some code into background_plot_debug.py, I can see that these large pixels are still present in the data.
So I can focus on the histogram routine now. Limiting the plot to counts above 10,000 and with a linear y axis, I can clearly see
counts now. The problem: many bins =1, which would be zero in a logy plot.

So I need to clean up the histograms in general now. 

Looks like I am having problems with the Am241 run. After processing many files, it chokes and eats up memory.
During the first try, it chocked on am241_6_11_2013_90msect6886.tif

Try again, and count the number of files input first. 
The program has stalled again on am241_6_11_2013_90msect6886.tif after half an hour. This was file 7858.
Delete (or move) the file, and try again.
7857 /proj3/Slimer/Slimer_mk2/6_11_2013/am241_6_11_2013_90msec/am241_6_11_2013_90msect3561.tif
This is the last file in the bunch. The problem is AFTER the files are loaded.
The problem is during the computation of the STD.
Actually, even getting past that, I can't save the npz file since it is larger than 2GB, and npz files can't be larger than that. 
I'll need to switch over to using HDF5 format!


Once I've taken a look at the pixel counts past 1,000 and compared the different data sets, I can move on. 
I don't see much of a difference in terms of the shape of the tail past 100 pixel counts. 
Plot them all over on top of each other, perhaps with a log plot, and see if the AMPLITUDE of the tail is different. 
I don't see much of a difference, if any. 
----> only the # of hot pixels is a unique observable, it seems


July 8th 2013 -------------------------------------------------------
We've switched from using wit's standard python distribution to using Anaconda. This gives us newer code. 
The new version of numpy CAN write out npz files larger than 2GB now. This is good, since using PANDAS is tricky...
I think I would have needed to use a Panel, instead of series or DataFrame since I was trying to store a 3D ndarry. 

I'm still having issues with calculating the STD though. Could be a bug. The variance actually works. The only difference is a sqrt, and perhaps some 
array manipulations. I've run background_average on all the 6_11_2013 data sets, so this step should be done.

It looks like numpy has trouble using nunmpy.load on large arrays. This is fixed with a new numpy, but I don't think I want to mess with that. 
It should work with Python3 though, so I could switch.

Reexamine what I wish to do. 
             Compute a background average: this code works
             Compute summary statistics: this code works
             Quickly scan through many files: use parallel computing. 
Eventually I will want to be able to scan through many image files and look at images that pass certain cuts. 
For THAT I'll need some complicated HDF5 stuff, NOT pandas which aren't setup for this type of thing. 

I committed my existing code to git, and will now par things down. 

The existing averaged images are fine to use however.                

I could still use Pandas for other observables. I could record:
file name, including the whole path
the number of hot pixels
location of peak
peak height
peak area
and so on.

July 9th 2013----------------------------------------------------
I have some analysis code running for images now. The location is here:
    ~/Work/SLIMER/AnalysisCode/ImageAnalysis/image_analysis.py
this can input multiple images, and subtracts the background using a NPZ file. 
The background subtraction was a bit tricky, as the unsigned 16 bit integers in the array wrap around when the background is higher than the source pixel. 
I got around this by using a mask array. 

I need to code in a peak finder now. I should consider writing a seperate class for this, and need to select a technique. 
ndimage.measurements may be useful here
scikit-image may be useful as well

Cluster Analysis in general might be useful.
So might blob detection
watershed may work in a median or gaussian blur is applied.
k-means clustering(in scikits-learn, scipy, or openCV, or scipy-cluster)
Otsu's method
scikit-learn's linear support vector machine in kernel (radial basis function)smode

I'm seeing evidence of clustering, even with a threshold of 0.5 sigma. 

To implement a k-means approach, I'll need to integrate itensity data into the algorithm.
One way to do this is to feed the algorithm each point N times, where N is the pixel count

July 10th 2013 --------------------------------------------------
I've got a test k-means script running, and have also been able to apply it to images.
The key with the scipy implementation is to NOT whiten the data.

It looks like using k=2 works fairly well, one cluster will be the peak, and the other will be the background and thus junk, with wide seperations 
Using kmeans for images with 70 or more hot pixels that are at least 0.75 sigma above background seems to work. 
Applying it to ALL images seems to work: images with no clear cluster seem to product distortions of 100 or greater, and only 50% of pixels 
are in one cluster. The images with clusters seem to have distortions < 20, and 80% or more pixels are in a cluster. 

So this may work, when cuts are applied to the output of the kmeans algorithm. 

July 11th 2013---------------------------------------------------
It looks like my background average routine is choking again....the arrays are simply too large. 
Instead, I'll need to compute a running average and variance instead, as detailed here:
http://en.wikipedia.org/wiki/Algorithms_for_calculating_variance

def online_variance(data):
    n = 0
    mean = 0
    M2 = 0
 
    for x in data:
        n = n + 1
        delta = x - mean
        mean = mean + delta/n
        M2 = M2 + delta*(x - mean)
 
    variance = M2/(n - 1)
    return variance
Okay...the new background average has been implemented. 

The k-means algorithm when run on 241Am data, seems to do a pretty good job of finding clusters: there are far more points in one cluster, 
and the distortion is far lower (~30 instead of ~150).

On C14 data, the fraction is picking up clusters. The distortion is high though: 120 pixels. At least for some.
The efficiency is quite low as well. The good news is that the the algorithm is picking up fairly low energy events. I think.
A fraction of .39 still produces a very noticeable cluster

July 12th 2013 ----------------------------------------------------
I've coded a DBSCAN implementation, but the memory use is REALLY bad. I think I can code my own implemenation using the original image matrix, and have it run much faster.
Or I could run ELKI externally.

I've coded my own implemenation, commited a new git revision, and then started to take out the use of the scipy revision.
At this point, I'm going to have to debug the new dbscan code, and the code that uses it. Then I'll have to see if it works.

I also need to look at the two images that Erik sent me: I need to make sure they are not from a sharp spike.

July 15th 2013-----------------------------------------------------
DBSCAN is kind of working, but is slow. 
profiling now:
sum uses 144 total time
dbscan uses 371 total time, of which
regionQuery uses 221.577
numpy reduce uses 144
zeros uses 195

Stop using zeros in regionQuery
Profile again:
sum is using 121
dbscan uses 302 total time
regionQuery uses 176
sum is using 122
reduce uses 122 (could be same thing, or could be formation of the reduced sqaure matrix ) 

Stop using sums everywhere.

dbscan now uses 175 total time  
regionQuery uses 173 total time!

Indexing the array IS faster than applying bounds manually to a much larger matrix.
I think my logic has some issues: I need to be sure I only work with non-zero pixels in my code. Doing otherwise makes things very slow, and perhaps incorrect!

July 16th 2013----------------
Fixed a problem with array indices in queryRegion. Now code is slow again.
Cna profile python code using this command:
python -m cProfile

a 'sum' instance is using 2.725, and has been called 1300 times 
dbscan is using 172.472 per iteration. Of this,
expandCluster is using 157
regionQuery now uses 14.
iterNext uses 13.197

Fixed a few bugs.
now profile again:
348.444 dbscan
320.179 expandCluster
40.927 regionQuery

expandCluster was iterating through the whole 512x512 matrix. Only iterate through the non-zero neighborhood!
Profile again:
71.914 dbscan
43.127 expandCluster
38.620 regionQuery
2.299 distanceQuery
Not clear how to speed things up now. 

DBSCAN is now finding clusters, but it is not recording the members correctly: each cluster has only 1 pixel, even if that pixel is NOT large enough to form a cluster
fixed a problem with expandCluster.
Now getting multiple pixels, but now getting clusters with no pixels!!!!!!!!!!!! Also getting clusters with too few counts.
Zero cluster problem went away once I fixed some logic in expandCluster.

It seems that points are being removed from clusters after the fact: and points marked as being parts of clusters are being marked as noise later, or as members of other clusters.
So I've still got the logic wrong.

July 17th 2013 ------------
Core points should never be removed from a cluster. But edge points can: they can be memembers of more than one cluster
Corrected a problem with the dbscan method: I should only use points that haven't yet been visited.
This seems to help: points are no longer being moved from one cluster to another.

Now clusters have more than one pixel, have a count above MinPTS. So things look better now!

Need a good way to check the code now. Should code up the ability to compute the density of a cluster, and the percentage of counts in a cluster as well.

July 19th 2013---------------
Clean up dbscan code, then the entire analysis code, and then begin to run it on background
July 23rd 2013---------------
Continue code cleanup.
Things are now running. Commit and continue.

DBSCAN takes ALOT of time between when it announces the number of clusters found and picking the best.
This time is spent on "analyze_results" and is due to the computation of the cluster position.

I've changed the code to compute the covariance matrix, which isn't used just yet. 
A code tweak sped up the computation of the variance nicely.

Now circle back and code in the ability to actually extract and save parameters.
For now, just write out the cluster parameters and the file path to the image. I can look at parameters and the image using another program.
I will however need to code in an option look at which pixels are in which clusters.

July 29th 2013----------------------------------
ascii and hdf5 output now work! Code committed!

It seems like something is trying to make an X connection however. That is NOT right!
It is okay....it is matplotlib.

July 31st 2013 -------------------------------
Found a problem with the threshold setting: I was multiplying the threshold in sigma by the variance, NOT the sigma
I'm seeing events with DBSCAN clusters < minPts. This implies a bug.
I've tweaked the DBSCAN requirements, and this seems to reject background more effectively.
However, the code runs MUCH longer now. 
Time to do some more profiling.....
regionQuery is eating up most of the time.
Of this, roughly a third is spent with distanceQuery.
Not much to do now.....

Aug 5th 2013 ------------------------------
I'll need to change the output code in case DBSCAN finds no clusters. 
For now, continue to add to the output code.
Aug 6th 2013 ------------------------------
Erik is seeing a difference in energy scale between different magnifications (10x and 20x).
The objectives that we have are:
CFI Pan Flour    MRH 00401   40xa   NA 0.75  WD 0.72
                 MRH 00201   20xa   NA 0.50  WD 2.1
                 MRH 00041   4xa    NA 0.13  WD 17.2
                 MRH 00101   10xa   NA 0.30  WD 16    
                 
Newport has a nice explaination of NA and general optics here:
http://www.newport.com/Tutorial-Light-Collection-and-Systems-Throughput/381845/1033/content.aspx

In the above, they relate flux (phi_c) to the F-number:
    phi_c approx 1/(F-number^2)
However the Numerical Aperture (NA) = 1/(2F-number)

so phi_c approx (2*NA)^2
So 10x -> 20x should produce (0.50/0.30)^2 = 2.78 more light! 

Aug 7th 2013 ------------------------------
slimer_ana is now done. Clean things up and think about what else is needed....
The only parallel part of the analyis chain is image_analysis. 
So I need to write:
    bash scripts for running background_average.py on specific datasets
    SGE scripts for running image_analysis.py on arbitrary datasets across the cluster
        a bash script for running image_analysis.py on a specific subset of data
    a bash script which runs the SGE script on specific datasets.
    a tool with which to sum multiple hdf5 files
    a bash script to run slimer_ana.py on a specific dataset.
    
The HDF5 summing tool is now written. 

Now write scripts.
I have a script ready to run image_analysis. I need to debug it. 


Find some data:
    /proj/Slimer/Slimer_mk2/8_01_2013/
write a script to do the background average:
    /proj/Slimer/Slimer_mk2/8_01_2013_mikes_ana/scripts/

background_average is disk, not CPU, bound. Implies should always be run on node3, and perhaps on local_scratch.
    Here was the output of that job:
    Number of Images: 10641
[[ 500.16398835  500.33239357  500.69702096 ...,  500.36152617
   503.47213608  503.08890142]
 [ 500.69523541  500.74570059  500.69702096 ...,  500.50765905
   502.88873226  502.63565454]
 [ 500.67249319  500.50089277  500.77145005 ...,  500.6090593   503.20740532
   502.64138709]
 ..., 
 [ 503.11728221  502.97190114  503.10064844 ...,  502.89239733
   505.58340382  505.10074241]
 [ 503.28991636  502.91701908  503.32609717 ...,  503.19641011  505.3452683
   505.42326849]
 [ 503.15026783  503.26567052  503.32027065 ...,  502.83168875
   505.49769758  505.26125364]] [[  90.29913913  142.25839511  220.79108981 ...,  123.63084669
   150.34793124  143.65638151]
 [ 144.07449703  139.51352122  134.81684169 ...,  149.93041596
   163.70453562  131.73650683]
 [ 144.41406379  132.83404526  156.7528352  ...,  131.96369236  157.2606444
   141.45014409]
 ..., 
 [ 174.73530374  128.54610888  126.51684262 ...,  153.4501687   165.95547266
   153.83063949]
 [ 135.2303203   157.43907217  215.51977846 ...,  147.23679538
   143.48641769  137.59413522]
 [ 153.59668437  240.25413059  897.17128925 ...,  158.69074761
   161.00189789  154.90711606]]

    
I now have other scripts in:
    /proj/Slimer/Slimer_mk2/8_01_2013_mikes_ana/scripts/    

now everything is pretty much working!    
    It DOES look lime hdf5_sum isn't working correctly: only one event is present. Or slimer_ana may be messed up.
    

Aug 8th 2013 -------------------------------------------------
It looks like the variance between pixels in the 8_01_2013 dataset is quite large!!!!!!!!!!!!!!!!!
does this make sense?????

Back to the analysis chain first. the summed HDF5 file seems to have 105 entries, so that part of the code should be working.
The problem seems to be in slimer_ana, namely the cut stage.

No, the problem is that ALL images are failing the DBSCan found clusters cut.
image_analysis IS finding "hot pixels", and many of them.
It looks like the problem is with DBSCAN.
Tweak minPts and eps from 1000 and 5.0 to 200 and 5.0.
Now I'm getting MANY clusters.
use 500 and 5.0.....now some clusters are found.

slimer_ana is now working .... kind of. 

Automatic histogram axis computation is NOT working in slimer_ana. Actually, it IS. there are some large outliers in the data.

Computation of the cluster position is NOT working all the time in image_analysis. There was a problem with the weighted mean calculation.
It has been fixed.

Aug 9th 2013 --------------------------------------------
We now have a new tool for nd2 --> tiff conversion. It is a library called Bio-Formats.
The command line tools are written in java, and conversion from the head node is SLOOOOW when reading and writing over NFS. 
I've installed icedtea java on all worker nodes to allow this tool to be run from node3, so NFS is not used. 
Now it is FAST....much more so than using the SLIMER DAQ machine. 

We want to compress the data down to monochrome, so the proper command is:
/proj/Software/ImageProcessing/bftools/bfconvert <path to nd2 file> <root_name>_%t.tiff

which will split the frames in the nd2 files, and append labels based on frame number

using <root_name>_%A.tiff instead will result in file stamps according to exposure time.
HOWEVER THE USE OF THE %A STAMP WILL ONLY GO DOWN TO THE SECOND, SO IMAGES WILL BE SUMMED INTO GROUPS OF SECONDS.

For full seperation, we'll need to use the %t tag.

Other information on bftools can be found here:
http://www.farsight-toolkit.org/wiki/FARSIGHT_Tutorials/Bio-Formats

Aug 10th 2013 ---------------------------------------------
Syncing git repos.
to update things FROM another repo (from say wit):
    git pull ronquest@wit.lanl.gov:/home/ronquest/Work/SLIMER <name of branch>
to push the updates back to the remote server (useful for when a pull FROM the remote server is not possible) do:
    git push ronquest@wit.lanl.gov:/home/ronquest/Work/SLIMER <name of branch>
note that one cannot push to a branch which is already checked out ON THE SERVER.
The way around this is to work on different branches between the serve and client.

So, form this point forward, I will leave the master branch alone, and develop in the branch mike_working.
Anyone who wants to collaborate should create their own repo, and THEN their own branch. And then push that branch to the server.
Note that they may need to create the branch on the server FIRST. 


Getting USB drive resets from the SLIMER drive when connected to wit. Need to find a place where this does NOT happen.

Looks like I finished analysis on no_source_8_01_2013_200msec.
What time spreads are present in the files? It looks like it takes about two hours to process everything. 
Running hdf5 sum......
Looks like I've got 10632 images......
....and 223 pass my cuts, with clustering set to MinPts=500/eps=5.0 (pixel density of ~ 6.41). 2% leakage. 
130 of these events have an average pixel count of les than 30 counts. 
Most pixels have < 1000 counts, and there is a spike at 500 counts!. On average, there are 27 pixels in a cluster.
On average the maximum peak height is 160 counts.

Aug 12th 2013 ----------------------------------------------
The bioformats tools bfconvert and showinfo have a memory limit wired into the scripts as an argument to java. 
I've copied them, and changed the memory limit to 5GB.
This appears to have worked. 

I've tarred up Mary's old files in Slimer_mk1. This will buy us some more space.

I'm transferring the nd2 files into Slimer_mk2/nd2_storage/

I'm running bfconvert_large on the c14 data from Aug 9th.
I'm doing the same to the background runs from the 8th and 9th.
In order to process the 10 hour background run, I'll need bump up the memory on bfconvert, again.
Try 15GB. That does not work either. 
I may need memory equal in size to the nd2 file!    Look at bfconvert again to see if I have options for partial conversion....
It looks like I do NOT. The entire nd2 file is loaded into memory it seems before any slices are processed. 
Since the newer worker nodes have 19GB of RAM and 37GB of swap....I could take things up to 56GB. But 20GB seems safer. 
That implies we could take data for a bit over two hours. 
Wait. the "%s" flag DOES work, and produces a large, but not as large tiff file if the -bigtiff tag is used.
Does %A work? YES. 
try again with %t. It works! 
The key is the -bigtiff tag! 
Next question: why are there only 12907 frames?????
run with the %A tag again, and see if that produces more frames.
With a ten hour run, there should be 36,000 frames. There are not. There are only 4385 frames: a bit more than an hour???!!!!

Tomorrow, I need to see if I can find any exports from Elements......does it extract a different number of frames, or extract 
from a different range of times?

Aug 13th 2013-------------------------------------------------
It appears that Elements does indeed export many more slices (up past 30,000) than bfconvert does. 
However, this is not a big deal, as we've figured out how to split things up into one hour runs. 

I strongly believe that I was converting the smaller background file rather than the large one last night, so the large background file
is still not useable. 

Run analysis again. Set minPts =175.0 eps=2.0 (25 pixels)
This really pumps up the background rate....

Go in the opposite direction:  Try 300.0, eps=2.0 
Still not much of an improvement. Try 700.0, eps=2.0
    ---> out of 2208 images, 35 have clusters
    --->  954 images, 12 have clusters. 
Aug 14th 2013------------------------------------------------
using bzip2 on nd2 files shrinks them to roughly 40% of their original size. Once they are converted, they should be bzipped
Lzma takes much longer, but does not result in a smaller filesize.


Aug 18th 2013-------------------------------------------------
Updated git repos between wit and my laptop.

Aug 19th 2013-------------------------------------------------
Run analysis on the background samples again. 
It appears as though the sample with the camera shutter closed as a SMALLER exponential tail than the other datasets. This implies
there is a light leak. I'll want to produce an overlay plot and ratio plot to illustrate this.

The data from 6_11 and 7_01 look quite different. 7_01 has a higher modial value, but a smaller width in the gaussian and a smaller and steeper exponential tail.
The 6_11 shows a jump from no_camera to no_lens, while the 7_01 data shows a jump from
no_camera to no_microscope.  

I'll need to try to find this light leak.....but plot the result of opening the camera shutter first. 

Aug 20th 2013 ------------------------------------------------
Collected a new light leak data set. Also found a leak in the door as well and tried to cover it up.
But first, I need to make room and reorganize the directories.
I've moved Eriks code and files to a few directories in Slimer_mk2
Now compress all tiff files into tarballs to save space.  

New procedure: nd2 files stay on /proj3, while the extracted tiffs go to 
/bigscratch4/ronquest/SLIMER/converted_data

I've already converted the data collected yesterday and today over to the above location.
I'm running the background_analysis.pyscript on these data now.
It appears that the tail for the light leak runs is the same...until I attempeted to close the drop cloth over the box, 
and until I closed the camera shutter.
At 542 counts:
wide open: 31530 events
hold_shut: 18929 events   --> 40% reduction from wide open
camera closed: 12732 events --> 60% reduction from wide open.
Working on the door is a clear prioroty. Seal the crap out of it and see if the tail can be reduced to the level of the 
camera shutter closed.


I'll need to move the 8_09_2013 directory to local_scratch for compression....
Once that is done, I'll have enough space to generate the tarballs for everything else.

Aug 22nd 2013 -----------------------------------------------------------------------
Compression of data should be complete. 
Next step is to check to see which datasets as also in .nd2 format
Copy the 8_09_2013 directory back to /proj3. Done. 
Now begin to delete the tiff files to make room on /proj3. I've got 170GB free, so can stop for now. 
/local_scratch/ronquest cleaned up.

I still need to clean up /local_scratch/super
and slimer_data.

Still working on fusing Erik's code with my own. Just have to work out how and what to output and store.
May also want to code ability to find multiple clusters for the analysis code: better efficiency and 
more compatible with observing multiple decays in a Phylochip

Aug 30th 2013 -------------------------------------------------------------------
I'll need to change things so that I write output after each image processed. The hdf5 file is in table mode, so I should be able to append it.
I've coped dbscan_analysis.py to dbscan_analysis.py_old: I'll need this code as I'll be forced to rip out the best cluster code
Actually, I don't need to remove the code, just not use it. 

Sep. 3rd 2013 -------------------------------------------------------
I just took more light leak data. Analyze it.
The files are:
door_taped_9_3_2013_200msec
shutter_open_9_3_2013_200msec
shutter_closed_9_3_2013_200msec

the nd2 files are in nd2_storage, while the converted tiffs are on 
/bigscratch4/ronquest/SLIMER/converted_data/

The pixel count distribution is NOT appreciably different with the camera shutter open and the door taped. 
It IS still different with the shutter closed. 
However, I left the light on. Power that down, and the stage, and take more data.

After sticking my head into the darkbox and taking a good look around, I've found an LED on the hub controller. Power that down shuts the light off.
I've taken more data, and the files are:
light_and_stage_on_scope_off_9_3_2013_200msec.nd2
scope_off_9_3_2013_200msec.nd2
door_taped_2_9_3_2013_200msec.nd2
light_and_stage_off_9_3_2013_200msec.nd2

---->RUNNING WITH THE SCOPE OFF RESULTS IN NEARLY THE SAME PIXEL COUNT DISTRIBUTION AS RUNNING WITH THE CAMERA SHUTTER CLOSED<--------------------
---->WHEN THE SCOPE IS OFF, THE LIGHT AND STAGE POWER HAVE NO EFFECT. <---------------------------------------------------------------------------
---->NOTE THAT THE CAMERA HAS A FLASHING LED WHEN THE SHUTTER IS CLOSED. SO SHUTTER CLOSED RUNS STILL MAY NOT BE THE BEST <-----------------------
---->I MAY BE SEEING EVIDENCE OF MORE OUTLIER EVENTS WITH DIFFERENT RUNS. THIS IS DIFFERENT THAT THE EXPONENTIAL TAIL I'VE BEEN FIGHTING. THESE ARE EVENTS WITH MORE THAN 700 COUNTS<--------

light and stage power don't seem to matter when the hub is on as well.

I've made a nice plot of the situation here:
/home/ronquest/Work/SLIMER/AnalysisCode/BackgroundStudy/lightLeak_overlay_09_03_2013_hub_smoking_gun.pdf

Sep. 6th 2013 ----------------------------------------------------------
Continuing to overhaul the output code. I've removed the ASCII code since I can always simply convert the HDF5 tables into ASCII format.
I will try to output the data into seperate HDF5 files in the same store. This enables me to avoid padding. 
Each analysis method will get its own table, and the file name of the image will be the index.
Commit the code as is and implement this new approach.

I'll need to modify the hdf5 sum code to handle this as well.  

I think I'm bumping into a problem with Erik's fitting code: in shaw_fit.py,  the method optimize.leastsq(errorfunction, moment)
I should take a close look at the values of errorfunction: it could be doing something nasty

Sep 8th 2013 ------------------------------------------------------------
Modifications to image_analysis.py are complete. I'm still having issues with Erik's fitting code, so I've disabled it for now. His cluster code DOES work though.
However, the output code does NOT. It works fine as long as each variable is a single value, but multiple element arrays are crashing the HDF5 code. I don't think
this is specific to shawcluster: the problem goes away if an index is not used. I may need an index per element. I do.
I need to check to see if using the same index in multiple rows would cause a problem. I don't think it will

Sep 9th 2013 -----------------------------------------------------------
I've taken data with various cables unplugged from the hub.
The data files are:
cables_in_9_9_2013_200msec.nd2
cables_out_9_9_2013_200msec.nd2
hub_off_9_9_2013_200msec.nd2
shutter_closed_9_9_2013_200msec.nd2
stage_in_9_9_2013_200msec001.nd2
stage_out_9_9_2013_200msec.nd2

I've converted and run analysis on the above. Two groups are formed:
high tail:
    cables_in_9_9_2013_200msec.nd2
    stage_in_9_9_2013_200msec001.nd2
    
    
low tail:
    cables_out_9_9_2013_200msec.nd2
    hub_off_9_9_2013_200msec.nd2
    shutter_closed_9_9_2013_200msec.nd2
    stage_out_9_9_2013_200msec.nd2

So the problem occurs when the stage is powered up!
It has "encoders" which are likely optical encoders. 
Two approaches: a usb or ethernet switch that can be used to power the hub on and off
Or use a filter cube that filters light of this wavelength.

It wasn't the stage that the cable powered, it was the filter wheel! The stage has no encoder. 
The filter turret is a TI-FLC-E.

I should run with both filter cubes to see if they can cut ALL the ambient light.
Run with:
no filter
one filter
the other filter
with the turret unplugged. 

Note that running with a filter will cut the CsI light..... 
Sept 10th 2013--------------------------------
Don't use the image name as the index for the other dataframes. This may create problems later.
Do add the image name as an extra column however.
Go ahead and DO use the index for General_ImageData. 

Sept 11th 2013 -------------------------------
I've run a test of scanning pandas DataFrames:
Using frame.loc['<index position>'] is 83 times faster than using:
frame[frame['<Index Column>'] == <index position>]

So index lookups are MUCH faster
I might be able to generate a dictionary of index position lists with the image name as a key. 
Plan on doing this.

The next step will be to modify slimer_ana.py to process the new tables 

Sept 12th 2013 ------------------------------------
Nikon Rep:

Christopher P Miller
Bioscience Sales Specialist

Nikon Instruments Inc.
12 Goodyear
Suite 110
Irvine CA 92618

Office: 949-586-9000    Fax: 949-586-4809
Mobile: 602-363-9689    Fax to Order: 631-944-9371
cmiller@nikon.net<mailto:cmiller@nikon.net>


They don't have notes on our account regarding what filter cube. 

He's drawing a blank regarding the filter turret off. Have to crack it open.

I need to see what 

He'll be at Los Alamos next week. 

======
Return to coding. Run analysis on a good set of C14.
Run analysis on:

am241_8_01_2013_200msec  
c14_8_01_2013_200msec    
no_source_8_01_2013_200msec  
09791
Now I need to update hdf5_sum.py....
DONE. 

It looks like some jobs fail: I need to add in the ability to fail files in hdf5_sum.py,
I can try to catch an exception, or there might be a better way of doing it
DONE.
Sep 15th 2013 --------------------------------------------
I'm running into an issue with slimer_ana.py
The hDF5 cut code is complicated when you wish to NOT apply a cut to a DataFrame.
I'm likely going to have to refactor the code so I don't operate on DataFrames that will not be cut.
Or figure out a way to use the logical operations to my benefit

Sep 18th 2013 -------------------------------------------
The new cut code now works on the new output format. 

A couple of bugs are showing up:
1) DBSCAN only finds two clusters, and ALWAYS finds two clusters.
2) Shawcluster variables are not being included: only the number of peaks found and the image path are being saved.
3) The index in the _ana hdf5 output files is screwed up. I'll need to regenerate the index before closing the file I think.
4) no_source data seems to have multiple histograms of the same name.
When looking at the crunched files (after summing), 1) is no longer true while 2) and  3) are still true

1) was due to the cuts I applied: the edges of the cut windows are not inclusive.
2) was due to leaving out most of the variables. This has been corrected.

Sep 25th 2013 ----------------------------------------------
I've collected some more data with the FITC filter in and out. This will tell us if a IR filter
in a filter cube is sufficient to block all the IR light from the filter turret. 

Convert these data files:

/proj3/Slimer/Slimer_mk2/nd2_storage/turret_off_FITC_out_9_25_2013_200msec.nd2
/proj3/Slimer/Slimer_mk2/nd2_storage/turret_on_FITC_in_9_25_2013_200msec.nd2
/proj3/Slimer/Slimer_mk2/nd2_storage/turret_on_FITC_out_9_25_2013_200msec.nd2

Done.

Now running analysis on them. 
The associated ROOT files are now in:
/proj/Slimer/SlimerAnalysis/background_study

It is clear that the FITC filter is blocking the majority of the light. Not everything, but nearly everything. 


Sep 30th 2013 ------------------------------------------------
The index problem in the HDF5 files is being introduced during the HDF5_sum stage.
The solution is to use the .reset_index(drop=True,inplace=True) method of DataFrames. 
hdf5_sum.py is modified.

Oct 3rd 2013 -------------------------------------------------
The script which runs image analysis seems to move things it shouldn't when using wildcards for the input files.
I've fixed this, and committed the new version.

Now I want to try to map out DBSCAN settings. 
Set#1
   minPts=500.
   eps=2.0
Doesn't see much.      
   minPts=500.
   eps=5.0
sees 45/107, including some with fewer than 500 counts ---> bug. 

Oct 17th 2013------------------------
We have the Thorlabs filter in hand now....but I can't remove the existing filter.
Need either a new filter cube, or a new 
Emitter Retaining Ring 
and
Emitter Housing / Emitter Mount Clip

Check thorlabs, semrock, Chris Miller and chroma.

Ask Semrock if they glue things in. Done. Also asked about seperate parts.
Emailed Chris.
Emailed Edmund Optics. --> don't sell the parts.
Emailed Thorlabs. --> don't sell the parts.
Emailed Chroma. ---> they may have a few parts available.

Oct 18th 2013-----------------------
Continue to iterate on code. 
DBSCAN is finding some clusters with LESS than the required number of counts. This is a bug.

Find this bug, and code in positions for Erik's cluster code.

Looks like I need to code in the ability to compute the mean and standard deviation of the cluster position --- 
Erik's code does not do this.    
I should code a generic cluster position finder and use it throughout the code.     

Oct 21st 2013---------------------
I've got the shawcluster code using my cluster finding code now. 
Now run it and make sure everything is working the way it should. 

It looks like I'm getting a negative variance on the cluster position in the X direction for some shawclusters. 
This could be due to the fact that all the "zero-count" pixels in Erik's code are actually slightly negative due to his thresholding
technique. This will wreck havoc with my code, although it doesn't impact Erik's energy estimates since he applies a thresholding requirement
in order to add to a cluster. 

In shaw_cluster, zero out negative pixels in the non-smoothed data array, just like Erik did with the smoothed array.
Yes, that did it. No more negative position variances!!!!!!!!!!!!!!!!

Can I add code to slimer_ana to use the new information? No need. 
Any other information missing in the shawcluster_analysis code?
Just the fraction of counts in a cluster and the average pixel value in the cluster. 
Add these now. Done.

Now go looking for the bug in my DBSCAN code which causes clusters to be found below threshold.

c14_8_01_2013_200msect02116.tif
is able to produce small cluster values

I've looked at dbscan_analysis.AnalyzeResults, and the cluster sums seems fine....no negative numbers, etc. 
Look at the dbscan info itself, but leave the debugging code in AnalyzeResults.

I think the pixelID code is working, so it isn't like pixels are being removed from clusters......
that implies the sum is wrong in the beginning (DBSCAN code) or later (in the cluster analysis code)

Looking at the DBSCAN code, I see that when array slicing is used in an iterator, the indexes reported are reletive to the SLICED array,
so the indices do NOT match from the original array and the sliced array. 
But I took that into account when writing the code.

The problem IS in the dbscan code itself. 
It occurs in ExpandCluster, neighborPixelSum is above the threshold. So something is wrong in that method.
But.......I do see one issue. regionQuery does NOT check the pixel ID, everything is included. 

It could be that the real criteria for a point to be in a cluster is the density of the area, which doesn't mean that the whole cluster will be a certain values
This isn't the case: edge points SHOULD be included in with a cluster.

I think the problem is that expandCluster enforces an eps requirement, but it operates on a reduced array already --- this should work in principle
and was put in to speed things up, however I may have introduced a bug.

Or, the pratice of NOT calling expandCluster for zero point may be the problem? No, all points should be included in the cluster.

Part of the problem is that Points can be used to bump the density up, but that are parts of other clusters. But most of the problem seems to lie elsewhere

Oct 22nd 2013---------------------------------------------------------------------------
It looks like the counts from regionQuery inside and outside of expandCluster may be different. 
No. Something else is going on.
Oct 23 2013 ----------------------------------------------------------------------------
I'm printing out the counts of the pixels added to a cluster.
For 
c14_8_01_2013_200msect02116.tif
cluster 4 has
4 507.184663096 at the first pixel, 
But
dbscanChecker: 4 27 27 490.96964571 500.0
after the cluster is built. 
use gawk to sum the pixels in this cluster:
grep "Adding to cluster  4 " test7.log | gawk '{sum+=$5} END {print sum}'

This returns just 469.73 counts, instead of 490?
dbscanChecker is picking up 27 pixels, which is the same number found by my debugging code. 
EPS = 8.0 

it looks like this cluster may be near to a boundary....closer than 8 pixels away.
However the boundary enforcement code looks okay and is present in regionQuery AND expandCluster.

I think this is the regionQuery info for the first call for cluster 4:
Calling regionQuery from expandCluster, for cluster 4
Adding  (8, 62)  to cluster with counts 11.8722864392 X
Adding  (8, 67)  to cluster with counts 9.15947749272 X
Adding  (9, 63)  to cluster with counts 21.1039375999 X
Adding  (9, 68)  to cluster with counts 13.8141152147 X
Adding  (10, 62)  to cluster with counts 11.9958650503 X
Adding  (10, 65)  to cluster with counts 24.9828963443 X
Adding  (10, 67)  to cluster with counts 13.1679353444 X
Adding  (11, 62)  to cluster with counts 11.2236631895 X
Adding  (11, 69)  to cluster with counts 27.1292171788 X
Adding  (12, 65)  to cluster with counts 9.90179494408 X
Adding  (12, 68)  to cluster with counts 12.8421201015 X
Adding  (13, 57)  to cluster with counts 9.43238417442 X
Adding  (14, 70)  to cluster with counts 13.8561225449 X
Adding  (15, 57)  to cluster with counts 10.9704914952 X
Adding  (15, 64)  to cluster with counts 13.2679259468 X
Adding  (15, 66)  to cluster with counts 11.1076026689 X
Adding  (16, 59)  to cluster with counts 9.7989850578 X
Adding  (16, 67)  to cluster with counts 41.8683394418 X
Adding  (16, 68)  to cluster with counts 49.0898411803 X
Adding  (16, 70)  to cluster with counts 16.9750023494 X
Adding  (17, 60)  to cluster with counts 10.9050841086
Adding  (19, 58)  to cluster with counts 12.9476552956
Adding  (19, 70)  to cluster with counts 75.8539610939 X
Adding  (20, 58)  to cluster with counts 10.8692792031
Adding  (20, 63)  to cluster with counts 14.8272718729
Adding  (21, 62)  to cluster with counts 16.7848886383
Adding  (21, 64)  to cluster with counts 9.69297998308
Adding  (21, 68)  to cluster with counts 11.7435391411 X
regionQuery inside expandCluster: (15, 64) 507.184663096



These are the counts reported for pixels in this batch.
13.2679259468 X
0.0
0.0
11.8722864392 X
9.15947749272 X
21.1039375999 X
13.8141152147 X
11.9958650503 X
24.9828963443 X
13.1679353444 X
11.2236631895 X 
27.1292171788 X
9.90179494408 X
12.8421201015 X
9.43238417442 X
13.8561225449 X
10.9704914952 X
11.1076026689 X
9.7989850578 X
41.8683394418 X
49.0898411803 X
16.9750023494 X
75.8539610939 X
11.9022648247
11.7435391411 X
9.85978761395
16.8108260502


So it looks like the first regionQuery has some pixels which do NOT find their way into the cluster.
It also looks like some other pixels are added to the cluster later, but that is expected. 

Grep for the pixel counts throughout the log file 
It looks like the missing pixels are NEVER added to anything. 
Oct 24th 2013------------------------------------------------------
It looks like they eventually are marked as -2: zero pixels! BUG!
It does look like that pixel is found to have zero counts at some point. However, later it has counts again.
This looks like a bug in the looping, and NOT a modification of the image array itself.
It looks like the addressing is okay. neighborPixels, which is being iterator over, is also zero at this point in the code. It must be wrong! 

I've confirmed this ---- the problem is with neighborPixels. The array must not be correctly set.
BUT it looks fine when expandCluster is first entered? This implies that neighborPixels is being modified or corrupted.

It looks like additional calls to expandCluster DO change neighborPixels. Or regionQuery does.
It is regionQuery ---- at this point in the code expandCluster is not called again. 

regionQuery uses neighborPixels as a variable name. However, there is no "self" so this should not corrupt things. 
but change the name anyway. This didn't help.

I've reverted the code in dbscan_analysis.py, with the debugging code saved in dbscan_analysis.py

Now use pdb to debug. 
adding a pdb.set_trace() like this:

if countsPrime:  # only do this for non-zero pixels <<My own logic>>                                                                                                              
                                pdb.set_trace()
                                neighborPixelsPrime,neighborPixelsSum = self.regionQuery(positionPrime)
                                #print neighborPixelsSum                                                    

I've confirmed that neighborPixels.sum() changes value when doing a 'next' through regionQuery.

id(neighborPixels) and id(neighborPixelsPrime) have the same value 
In Cpython, this is the address of the object in memory.
Always, this should be different for two different objects with overlapping lifetimes.
So something is getting linked.

self.tempPixels in regionQuery has the same ID as neighborcounts

I see the problem now! regionQuery has this line:
    neighborPixels = self.tempPixels,
    which is NOT copy by value. this means that neighborPixels is the SAME object as self.tempPixels I think. 
It is. 
I've added this line to regionQuery:
neighborPixels = (self.tempPixels).copy()

which fixes (part) of the problem. I'm still seeing clusters with counts < 500, but that could be due to overlaps and edge pixels.
Commit and continue debugging.

Cluster 44 is now a small cluster. 

dbscanChecker: 44 63 63 1058.8838455 500.0

grep "Adding to cluster  44 " test1.log | gawk '{sum+=$5} END {print sum}'
855.71

grep "Adding to cluster  44 " test1.log | wc -l
59

Cluster  44  contains  14.0  pixels and  196.929141998 counts

So everything seems inconsistent. Leave this for now. I may want to call dbscanChecker for cluster 44 for each incremented cluster to make sure it is NOT changing.
It doesn't ?

Oct 28th 2013 -------------------------------------------------
The result from dbscanChecker does NOT change throughout the run.
dbscanChecker reports 63 pixels added to cluster 44. 

while this reports
grep "Adding to cluster  44 " test1.log | grep -v "0.0" wc -l
48

and AnalyzeResults reports just
14.0
The DBSCAN Cluster Debug code agrees. 


Wait.  Analyze Results reports the cluster info for pixelID = ClusterID+1!!!!!!!!!!!
And:
Cluster  45  contains  60.0  pixels and  957.063527864 counts

AnalyzeResults reports that cluster 44 is low, so I want to look at pixelID=45 

Again:

Cluster  44  contains  14.0  pixels and  196.929141998 counts

grep "Adding to cluster  45 " test1.log | gawk '{sum+=$5} END {print sum}'   ----> 135.409
grep "Adding to cluster  45 " test3.log | wc -l                              ----> 10 

Missing 4 pixels ? I don't see how these get added in. 

Look at DBSCAN Cluster Debug:
DBSCAN Cluster Debug: 44 (157, 79) 10.4966638474 10.4966638474
DBSCAN Cluster Debug: 44 (158, 71) 10.5647965417 21.0614603891
DBSCAN Cluster Debug: 44 (158, 72) 10.855464712 31.916925101
DBSCAN Cluster Debug: 44 (158, 73) 14.5522977164 46.4692228174
DBSCAN Cluster Debug: 44 (158, 76) 10.775303073 57.2445258904
DBSCAN Cluster Debug: 44 (158, 79) 10.6196786016 67.8642044921
DBSCAN Cluster Debug: 44 (159, 74) 11.7407198572 79.6049243492
DBSCAN Cluster Debug: 44 (159, 76) 11.4874541866 91.0923785359
DBSCAN Cluster Debug: 44 (159, 77) 14.8405225073 105.932901043
DBSCAN Cluster Debug: 44 (159, 80) 10.6770980171 116.60999906
DBSCAN Cluster Debug: 44 (159, 83) 12.5791748896 129.18917395
DBSCAN Cluster Debug: 44 (160, 77) 43.6238135514 172.812987501
DBSCAN Cluster Debug: 44 (163, 79) 11.6772859694 184.490273471
DBSCAN Cluster Debug: 44 (163, 85) 12.4388685274 196.929141998



Adding  (150, 71)  to cluster with counts 17.4524950663  with ID -2.0
Adding  (151, 74)  to cluster with counts 9.77934404661  with ID -2.0
Adding  (152, 67)  to cluster with counts 12.7072643549  with ID -2.0
Adding  (152, 73)  to cluster with counts 11.5928014284  with ID -2.0
Adding  (152, 75)  to cluster with counts 12.6345268302  with ID -2.0
Adding  (153, 67)  to cluster with counts 9.89484071046  with ID -2.0
Adding  (153, 75)  to cluster with counts 49.6755004229  with ID -2.0
Adding  (153, 76)  to cluster with counts 10.7058547129  with ID -2.0
Adding  (154, 68)  to cluster with counts 10.5288036839  with ID -2.0
Adding  (154, 71)  to cluster with counts 16.7578235128  with ID -2.0
Adding  (155, 66)  to cluster with counts 10.0038530213  with ID -2.0
Adding  (155, 67)  to cluster with counts 13.6548256743  with ID -2.0
Adding  (156, 65)  to cluster with counts 10.6737148764  with ID -2.0
Adding  (158, 71)  to cluster with counts 10.5647965417  with ID 45.0
Adding  (158, 72)  to cluster with counts 10.855464712  with ID 0.0
Adding  (158, 73)  to cluster with counts 14.5522977164  with ID 0.0
Adding  (158, 76)  to cluster with counts 10.775303073  with ID 0.0
Adding  (158, 79)  to cluster with counts 10.6196786016  with ID 0.0
Adding  (159, 65)  to cluster with counts 13.8378911756  with ID 0.0
Adding  (159, 69)  to cluster with counts 26.7640259374  with ID 0.0
Adding  (159, 71)  to cluster with counts 10.6958932431  with ID 0.0
Adding  (159, 74)  to cluster with counts 11.7407198572  with ID 0.0
Adding  (159, 76)  to cluster with counts 11.4874541866  with ID 0.0
Adding  (159, 77)  to cluster with counts 14.8405225073  with ID 0.0
Adding  (160, 68)  to cluster with counts 10.9532938634  with ID 0.0
Adding  (160, 70)  to cluster with counts 18.7978573442  with ID 0.0
Adding  (160, 77)  to cluster with counts 43.6238135514  with ID 0.0
Adding  (163, 69)  to cluster with counts 15.9469974626  with ID 0.0
Adding  (164, 68)  to cluster with counts 8.74006202424  with ID 0.0
Adding  (164, 71)  to cluster with counts 71.5684616108  with ID 0.0
Adding  (164, 72)  to cluster with counts 11.572972465  with ID 0.0
regionQuery inside expandCluster: (158, 71) 523.999154215


It looks like there are pixels marked with pixelID = -2, but they are NOT zero! BUG.
The code is in expandCluster, it sets pixels to zero by only checking neighborPixels ---> but these get zeroed out if they are out of range.
I'm also setting these pixels as Visited, which is wrong.  

Pull the PixelVisited modification inside the if counts loop, this way ONLY pixels within range are marked as visited.
check the value of imageArray for zero pixels in neighborPixels. If it is also zero there, set pixelID=-2.
Also, mark the pixel as visited, but that assume that zero pixels can't be the seed for clusters, so be careful

Making the change results in some very small clusters now, with few pixels. Could be edge cases perhaps. 

Look at the info.

Cluster  6  contains  2.0  pixels and  29.1291232027 counts
 

grep "Adding to cluster  7 " test1.log | gawk '{sum+=$5} END {print sum}'     ---> 842.212

grep "Adding to cluster  7 " test1.log | wc -l   ---> 64

DBSCAN Cluster Debug reveals:

DBSCAN Cluster Debug: 6 (40, 342) 14.1503618081 14.1503618081
DBSCAN Cluster Debug: 6 (48, 336) 14.9787613946 29.1291232027

Calling regionQuery from expandCluster, for cluster 7
Adding  (32, 342)  to cluster with counts 70.125740062  with ID 6.0
Adding  (33, 342)  to cluster with counts 17.2285499483  with ID 6.0
Adding  (34, 339)  to cluster with counts 10.3838924913  with ID 6.0
Adding  (34, 344)  to cluster with counts 29.1318485105  with ID 6.0
Adding  (34, 345)  to cluster with counts 13.1707546283  with ID 6.0
Adding  (35, 347)  to cluster with counts 10.2175547411  with ID 6.0
Adding  (36, 338)  to cluster with counts 11.2101306268  with ID 6.0
Adding  (36, 348)  to cluster with counts 9.20834508035  with ID 6.0
Adding  (37, 344)  to cluster with counts 9.03589888169  with ID 6.0
Adding  (38, 340)  to cluster with counts 11.1404943144  with ID 6.0
Adding  (38, 341)  to cluster with counts 10.1677473922  with ID 6.0
Adding  (40, 342)  to cluster with counts 14.1503618081  with ID 7.0
Adding  (40, 343)  to cluster with counts 12.1432196222  with ID 6.0
Adding  (40, 350)  to cluster with counts 10.2719669204  with ID 6.0
Adding  (41, 339)  to cluster with counts 13.9932337186  with ID 6.0
Adding  (41, 341)  to cluster with counts 9.18767033174  with ID 6.0
Adding  (41, 345)  to cluster with counts 9.12010149422  with ID 6.0
Adding  (41, 347)  to cluster with counts 12.0073301381  with ID 6.0
Adding  (42, 339)  to cluster with counts 10.9807348933  with ID 6.0
Adding  (42, 343)  to cluster with counts 15.6471196316  with ID 6.0
Adding  (42, 345)  to cluster with counts 31.7322620055  with ID 6.0
Adding  (42, 347)  to cluster with counts 90.2435861291  with ID 6.0
Adding  (43, 345)  to cluster with counts 11.8445634809  with ID 6.0
Adding  (44, 337)  to cluster with counts 36.0331735739  with ID 6.0
Adding  (44, 347)  to cluster with counts 14.8557466404  with ID 6.0
Adding  (45, 340)  to cluster with counts 11.94220468  with ID 6.0
Adding  (46, 342)  to cluster with counts 12.8498261442  with ID 6.0
Adding  (46, 347)  to cluster with counts 14.9661685932  with ID 6.0
regionQuery inside expandCluster: (40, 342) 532.990226482
Skipping point: (32, 334) 0.0 -2.0

Odd. It looks like expandCluster is not functioning properly---it should have picked up 40, 342 and assigned it to cluster 6.

Doing this:
grep  "(40, 342)" test4.log
reveals:
Adding  (40, 342)  to cluster with counts 14.1503618081  with ID 0.0
Adding  (40, 342)  to cluster with counts 14.1503618081  with ID 0.0
Adding  (40, 342)  to cluster with counts 14.1503618081  with ID 0.0
Adding  (40, 342)  to cluster with counts 14.1503618081  with ID 0.0
Adding  (40, 342)  to cluster with counts 14.1503618081  with ID 0.0
Adding  (40, 342)  to cluster with counts 14.1503618081  with ID 0.0
Adding  (40, 342)  to cluster with counts 14.1503618081  with ID 0.0
Adding  (40, 342)  to cluster with counts 14.1503618081  with ID 0.0
Adding  (40, 342)  to cluster with counts 14.1503618081  with ID 0.0
Adding  (40, 342)  to cluster with counts 14.1503618081  with ID 0.0
Adding  (40, 342)  to cluster with counts 14.1503618081  with ID 0.0
Adding  (40, 342)  to cluster with counts 14.1503618081  with ID 0.0
Adding  (40, 342)  to cluster with counts 14.1503618081  with ID 0.0
Adding  (40, 342)  to cluster with counts 14.1503618081  with ID 6.0
Adding  (40, 342)  to cluster with counts 14.1503618081  with ID 6.0
Adding  (40, 342)  to cluster with counts 14.1503618081  with ID 6.0
Adding  (40, 342)  to cluster with counts 14.1503618081  with ID 6.0
Adding  (40, 342)  to cluster with counts 14.1503618081  with ID 6.0
Adding  (40, 342)  to cluster with counts 14.1503618081  with ID 6.0
Adding  (40, 342)  to cluster with counts 14.1503618081  with ID 6.0
Adding  (40, 342)  to cluster with counts 14.1503618081  with ID 6.0
Adding  (40, 342)  to cluster with counts 14.1503618081  with ID 6.0
Adding  (40, 342)  to cluster with counts 14.1503618081  with ID 6.0
Adding  (40, 342)  to cluster with counts 14.1503618081  with ID 6.0
Adding  (40, 342)  to cluster with counts 14.1503618081  with ID 6.0
Adding  (40, 342)  to cluster with counts 14.1503618081  with ID 6.0
Adding  (40, 342)  to cluster with counts 14.1503618081  with ID 6.0
Adding  (40, 342)  to cluster with counts 14.1503618081  with ID 6.0
Adding  (40, 342)  to cluster with counts 14.1503618081  with ID 6.0
Adding  (40, 342)  to cluster with counts 14.1503618081  with ID 7.0

This logging is from regionQuery, and is from :
    print "Adding ",positionPrime, " to cluster with counts",countsPrime, " with ID", self.pixelID[positionPrime]
So pixelID is being modified now. 
Either pixelVisited is NOT being set for this point, so that the pixelID was set previously, and is being overwritten in dbscan (in the very beginning of expandCluster actually) 
or....there's a larger bug present. 

in dbscan itself, the point getting set can only be used to seed expandCluster (and thus pixelID be set) if it has been marked as visited.  
So the problem should be in expandCluster.
But it doesn't appear to be. 

I think the addressing may be off: I don't know when this point is marked as belonging to pixelID =6.0s
I'll need to watch this particular value closely.

It looks like the pixel is set when it is out of range of regionQuery. Because of this, the pixelID=0 and pixelVisited=0.0. 
I see the problem: points out of range of regionQuery are zero, but will NOT be marked as a zero pixel. This broke the logic. 

Revert code and try to fix the problem.

I've refactored the code in expandCluster. It looks like things work now!!!!!
Check the results, and look closer at the new overlap code.

Oct 29th 2013--------------
After a small tweak to the overlap code, things are looking good. 
Commit.
Now I'll need to run the code again and find good DBSCAN parameters.
 




































----
Now circle back to tweaking the input parameters for dbscan. 
I may want to code up a small script to print out the number of clusters found by Erik's code, and my DBSCAN code.






























































It looks like some image_analysis.py jobs are using LOTS of memory. 
Let me try to determine which these are...
am214---01525.tif is one.
no_source --09794.tif is another ---> problem is with kmeans
            09788.tif is another ---> kmeans eats up alot of memory, but terminates, but seems to kill dbscan  
            09791.tif is another     
these jobs also run for a LONG time.













 













data set          mean      std      median   mode   
----------------------------------------------------








I've looked at the 241Am source data from 8_01. I see very little difference compared to the background data, except the
rate of detection is much higher (For the 214Am data, there are 2797 images with clusters, out of 10064) 
So right now, with the current cluster settings, I get clusters of the same characteristics as the background, but at a different rate. 
This is the same thing that Erik was seeing. Crap.

Fix the hot pixel calculation first.



I'll need to make sure that the different runs are not different lengths clock-wise. It is possible that CsI scintillation events are causing triggers, but that the pre-clearing stuff 
is being run and that the exposure is not taken until after the scintillation light is gone.




If there is low level contamination, it may be interesting to compare a run with and without the CsI.
These files already exist however.....




  




















 
	




===========================
Check to make sure bfconvert is getting all exposures.


Study pixel to pixel variances. 

I will however need to code in an option look at which pixels are in which clusters.
I should be able to find the "good cluster" by averging the distance for all points, and picking the one with the smaller average distance. 




I should check to make sure that events that appear to be real events don't also have more hit pixels in the background as well. 


The next step is to PLOT the images, setting pixels less than say 3,4,or 5 sigma equal to zero, and setting the other pixels to maximum amplitude.
Do this for all datasets in order to look at the distribution of hot pixels. 
I want to see if the hot pixels are clustered in any way.


Given the hot pixel observation, I should take some more data with the camera shutter closed, by:
having the box open
having the box closed (we've done with before)
having the box closed and covered
having the box closed and covered, and the lights off downstairs (need to cover screen, and use delay in data taking)      
      
      
      
      
                  
            
           
           
            




























 





 









